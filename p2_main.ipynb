{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: CAVs and scenicness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geoplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-177-24e449ac19e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#for maps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgeoplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'geoplot'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pickle\n",
    "import collections\n",
    "import nbimporter\n",
    "import cv2\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import tqdm\n",
    "import glob\n",
    "import re\n",
    "\n",
    "#for maps\n",
    "import geopandas\n",
    "import geoplot\n",
    "\n",
    "from skimage import io, transform\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import utils, transforms, models\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "from sklearn import linear_model, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statistics import mean, stdev\n",
    "from scipy import stats\n",
    "\n",
    "from p1_CreateTrainingDataframe import CreateTrainingDataframe\n",
    "from p1_CreateTestDataframe import CreateTestDataframe\n",
    "from p1_BrodenDataSet import BrodenDataset\n",
    "from p1_RescaleImage import Rescale\n",
    "from p1_TransformToTensor import ToTensor\n",
    "from p1_GetVectorFromImage import GetVector\n",
    "from p1_GetCosineSimilarityDistance import GetCosineSimilarityDistance\n",
    "from p1_MakeVectorDictionary import MakeVectorDictionary\n",
    "from p1_SubsetConceptImages import SubsetConceptImages\n",
    "\n",
    "from p2_SoN_Dataset import SonDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary elements from part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "basenet = models.resnet50(pretrained=True, progress=True)\n",
    "out_layer = basenet._modules.get('avgpool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## my own laptop:\n",
    "# broden_dataset_path = '../data/broden1_384/'\n",
    "\n",
    "## on guanabana:\n",
    "broden_dataset_path = '/raid/data/datasets/broden1_384'\n",
    "\n",
    "index_file_path = os.path.join(broden_dataset_path, 'index.csv')\n",
    "label_file_path = os.path.join(broden_dataset_path, 'label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_path = '../data/training_data.csv'\n",
    "filtered_training_data_path = '../data/filtered_training_data.csv'\n",
    "test_data_path = '../data/test_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(training_data_path, sep=',')\n",
    "filtered_training_data = pd.read_csv(filtered_training_data_path, sep=',')\n",
    "test_data = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_broden_dataset = BrodenDataset(csv_file = training_data_path, \n",
    "                               data_path = broden_dataset_path, \n",
    "                               transform = transforms.Compose([Rescale(224),\n",
    "                                                              ToTensor(),\n",
    "                                                               transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                                    std=[0.229, 0.224, 0.225])\n",
    "                                                              ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_broden_dataset = BrodenDataset(csv_file = test_data_path,\n",
    "                                    data_path = broden_dataset_path, \n",
    "                                    transform = transforms.Compose([Rescale(224),\n",
    "                                                                    ToTensor(),\n",
    "                                                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                                         std=[0.229, 0.224, 0.225])\n",
    "                                                                   ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_idxs = list(range(len(training_data)))\n",
    "test_idxs = list(range(len(test_data)))\n",
    "\n",
    "training_tensors_filename = 'training_tensors.pickle'\n",
    "test_tensors_filename = ' test_tensors.pickle'\n",
    "\n",
    "with open(os.path.join('../data/', training_tensors_filename), 'rb') as handle:\n",
    "    training_tensors = pickle.load(handle)\n",
    "    \n",
    "with open(os.path.join('../data/', test_tensors_filename), 'rb') as handle:\n",
    "    test_tensors = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch CAV class for Scenic-Or-Not images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SonTorchCAV(object):\n",
    "    \n",
    "    def __init__(self, scenicness, num_son_imgs, num_counter_imgs, son_tensors, votes_df):\n",
    "        ''' \n",
    "        scenicness (string); low (1 - 4), medium (4 - 7.5) or high ( 7.5 - 10)\n",
    "        '''\n",
    "        \n",
    "        self.scenicness = scenicness\n",
    "        self.num_son_imgs = num_son_imgs\n",
    "        self.num_counter_imgs = num_counter_imgs\n",
    "        self.son_tensors = son_tensors\n",
    "        self.votes_df = votes_df\n",
    "        \n",
    "        self.train_df, self.test_df = train_test_split(votes_df, test_size = 0.3, train_size = 0.7) \n",
    "        \n",
    "        self.lm = None\n",
    "        self.cav = None\n",
    "        self.X_test = None\n",
    "        self.y_test = None\n",
    "        self.y_predict = None\n",
    "        self.accuracy = None\n",
    "        \n",
    "        if self.scenicness != 'low' and self.scenicness != 'medium' and self.scenicness != 'high':\n",
    "            raise ValueError ('scenicness is wrongly defined. Got \"%s\" but expected \"low\", \"medium\" or \"high\"' % self.scenicness)\n",
    "\n",
    "    def get_son_indices(self):\n",
    "            \n",
    "        if self.scenicness == 'high':\n",
    "            self.son_idxs = list(self.train_df.loc[self.train_df.Average >= 80,].index)\n",
    "        elif self.scenicness == 'medium':\n",
    "            self.son_idxs = list(self.train_df.loc[self.train_df.Average >= 40 and self.train_df.Average < 80].index)\n",
    "        else:\n",
    "            self.son_idxs = list(self.train_df.loc[self.train_df.Average < 40].index)\n",
    "        \n",
    "    def get_random_son_images(self):\n",
    "        \n",
    "        self.get_son_indices()\n",
    "        \n",
    "        if self.num_son_imgs > len(self.son_idxs):\n",
    "            self.num_son_imgs = len(self.son_idxs)\n",
    "        \n",
    "        self.random_son_idxs = random.sample(self.son_idxs, self.num_son_imgs)\n",
    "        \n",
    "    def get_random_counter_images(self):\n",
    "        \n",
    "        self.get_son_indices()\n",
    "        self.random_counter_idxs = list([i for i in np.asarray(self.train_df.index) if i not in self.son_idxs])\n",
    "        \n",
    "        if len(self.random_counter_idxs) < self.num_counter_imgs:\n",
    "            self.num_counter_imgs = len(self.random_counter_idxs)\n",
    "        \n",
    "        self.random_counter_idxs = random.sample(self.random_counter_idxs, self.num_counter_imgs)\n",
    "        \n",
    "    def train_lm(self):\n",
    "        '''\n",
    "        Train a linear classifier between the concept images and the counter images\n",
    "        '''\n",
    "        \n",
    "        self.get_random_son_images()\n",
    "        self.get_random_counter_images()\n",
    "        \n",
    "        # concatenate the tensors of the selected concept images into a matrix\n",
    "        self.train_son_tensors = self.son_tensors[str(self.random_son_idxs[0])].unsqueeze(0)\n",
    "        for i in range(1, self.num_son_imgs):\n",
    "            self.temp_son_tensor = self.son_tensors[str(self.random_son_idxs[i])].unsqueeze(0)\n",
    "            self.train_son_tensors = torch.cat((self.train_son_tensors, self.temp_son_tensor),0)\n",
    "        \n",
    "        # concatenate the tensors of the selected counter images into a matrix\n",
    "        self.counter_tensors = self.son_tensors[str(self.random_counter_idxs[0])].unsqueeze(0)\n",
    "        for i in range(1, self.num_counter_imgs):\n",
    "            self.temp_counter_tensor = self.son_tensors[str(self.random_counter_idxs[i])].unsqueeze(0)\n",
    "            self.counter_tensors = torch.cat((self.counter_tensors, self.temp_counter_tensor), 0)\n",
    "        \n",
    "        # concatenate all tensors to the same array\n",
    "        self.X = torch.cat((self.train_son_tensors, self.counter_tensors), 0)\n",
    "        self.X = self.X.numpy()\n",
    "        \n",
    "        # create labels for the tensors\n",
    "        # 1 = concepts, 0 = not concept\n",
    "        self.y = np.ones(self.num_son_imgs)\n",
    "        self.y = np.append(self.y, np.zeros(self.num_counter_imgs))\n",
    "        \n",
    "        # fit a linear classifier\n",
    "        self.lm = linear_model.SGDClassifier()\n",
    "        self.lm.fit(self.X, self.y)\n",
    "        \n",
    "        # the vector of coeffiecients are orthogonal to the decision hyperplane, thus this vector is the CAV\n",
    "        self.cav = self.lm.coef_\n",
    "        \n",
    "    def create_test_data(self):\n",
    "        \n",
    "        ''' \n",
    "        Creates test data. All tensors from the test data are concatenated and saved as a .npy file.\n",
    "        '''\n",
    "        \n",
    "        self.test_idxs = list(self.test_tensors.keys())\n",
    "        \n",
    "        if os.path.exists('../data/test_data_matrix.npy'):\n",
    "            self.X_test = np.load('../data/test_data_matrix.npy')\n",
    "        else:\n",
    "            self.X_test = self.test_tensors[self.test_idxs[0]].unsqueeze(0)\n",
    "            for idx in tqdm.tqdm_notebook(range(1, len(self.test_idxs))):\n",
    "                self.X_test = torch.cat((self.X_test, self.test_tensors[self.test_idxs[idx]].unsqueeze(0)),0)\n",
    "        \n",
    "            self.X_test = self.X_test.numpy()\n",
    "            np.save('../data/test_data_matrix.npy', self.X_test)\n",
    "            \n",
    "        self.y_test = self.test_dataframe[self.concept].values.astype('int')\n",
    "        \n",
    "        \n",
    "    def predict(self):\n",
    "        '''\n",
    "        Uses the linear classifier to predict the test data, also calculates the average accuracy.\n",
    "        Calls the function to create test data\n",
    "        '''\n",
    "        \n",
    "        ## To test on the 'scene concepts' change to X_scene_test and y_scene_test\n",
    "        # self.create_scene_test_data()\n",
    "        \n",
    "        self.create_test_data()\n",
    "        self.y_pred = self.lm.predict(self.X_test)\n",
    "        #self.probability = self.lm.predict_proba(self.X_test)\n",
    "        \n",
    "        # calculate true negatives and true positives for average accuracy\n",
    "        self.total_negatives = len(self.y_test[self.y_test == 0])\n",
    "        self.true_neg = 0\n",
    "        for i in range(len(self.y_pred)):\n",
    "            if self.y_pred[i] == 0 and self.y_test[i] == self.y_pred[i]:\n",
    "                self.true_neg += 1\n",
    "        \n",
    "        self.total_positives = len(self.y_test[self.y_test == 1])\n",
    "        self.true_pos = 0\n",
    "        for i in range(len(self.y_pred)):\n",
    "            if self.y_pred[i] == 1 and self.y_test[i] == self.y_pred[i]:\n",
    "                self.true_pos += 1\n",
    "        \n",
    "        self.accuracy = metrics.accuracy_score(self.y_test, self.y_pred)\n",
    "        self.score = self.lm.score(self.X_test, self.y_test)\n",
    "        if self.total_negatives != 0 and self.total_positives != 0:\n",
    "            self.average_accuracy = ((self.true_neg/self.total_negatives) + (self.true_pos/self.total_positives)) / 2\n",
    "        else:\n",
    "            self.average_accuracy = self.accuracy\n",
    "            \n",
    "    def view_son_images(self):\n",
    "        '''\n",
    "        View the concept images used to train the linear classifier\n",
    "        '''\n",
    "        \n",
    "        if len(self.random_son_idxs) == 0:\n",
    "            raise ValueError ('No images have been selected yet')\n",
    "        \n",
    "        else:\n",
    "            %matplotlib inline\n",
    "            dim = math.floor(math.sqrt(len(self.random_son_idxs))) \n",
    "            \n",
    "            fig = plt.figure(figsize=(12,12))\n",
    "            ax = [fig.add_subplot(dim, dim, i+1) for i in range(dim**2)]\n",
    "\n",
    "            for idx, a in enumerate(ax):\n",
    "                img_file = []\n",
    "                img_name = self.train_df.loc[self.random_son_idxs[idx], 'ID'].astype(str)\n",
    "                for directory, _ , _ in os.walk('/raid/data/datasets/SoN/images'):\n",
    "                    img_file.extend(glob.glob(os.path.join(directory, img_name + '.jpg')))\n",
    "                \n",
    "                img = plt.imread(img_file[0])\n",
    "                a.axis('off')\n",
    "                a.imshow(img)\n",
    "\n",
    "            fig.subplots_adjust(wspace=0, hspace=0)\n",
    "            plt.show()\n",
    "            \n",
    "    def view_counter_images(self):\n",
    "        '''\n",
    "        View the counter images used to train the linear classifier\n",
    "        ''' \n",
    "        \n",
    "        if len(self.random_counter_idxs) == 0:\n",
    "            raise ValueError ('No counter images have been selected')\n",
    "            \n",
    "        else:\n",
    "            %matplotlib inline\n",
    "            dim = math.floor(math.sqrt(len(self.random_counter_idxs)))\n",
    "\n",
    "            fig = plt.figure(figsize=(12,12))\n",
    "            ax = [fig.add_subplot(dim, dim, i+1) for i in range(dim**2)]\n",
    "\n",
    "            for idx, a in enumerate(ax):\n",
    "                img = plt.imread(os.path.join('/raid/data/datasets/broden1_384/images/', \n",
    "                                              training_data.loc[self.random_counter_idxs[idx], 'image']))\n",
    "                a.axis('off')\n",
    "                a.imshow(img)\n",
    "\n",
    "            fig.subplots_adjust(wspace=0, hspace=0)\n",
    "            plt.show()\n",
    "        \n",
    "        \n",
    "    def view_FN(self):\n",
    "        '''\n",
    "        View the false negative images of the linear classifier\n",
    "        '''\n",
    "        \n",
    "        self.FN = []\n",
    "        self.FN_idxs = []\n",
    "        \n",
    "        for i in range(len(self.y_pred)):\n",
    "            if self.y_pred[i] == 0 and self.y_test[i] != self.y_pred[i]:\n",
    "                self.FN.append(i)\n",
    "        \n",
    "        self.FN_idxs = list(map(lambda x: self.test_scene_idxs[x], self.FN))\n",
    "                       \n",
    "        %matplotlib inline\n",
    "        dim = math.floor(math.sqrt(len(self.FN_idxs)))\n",
    "\n",
    "        fig = plt.figure(figsize=(12,12))\n",
    "        ax = [fig.add_subplot(dim, dim, i+1) for i in range(dim**2)]\n",
    "\n",
    "        for idx, a in enumerate(ax):\n",
    "            img = plt.imread(os.path.join('/raid/data/datasets/broden1_384/images/', \n",
    "                                          self.test_dataframe.loc[int(self.FN_idxs[idx]), 'image']))\n",
    "            a.axis('off')\n",
    "            a.imshow(img)\n",
    "\n",
    "        fig.subplots_adjust(wspace=0, hspace=0)\n",
    "        plt.show()\n",
    "   \n",
    "    def view_FP(self):\n",
    "        '''\n",
    "        View false positive images of the linear classifier\n",
    "        '''\n",
    "        \n",
    "        self.FP = []\n",
    "        self.FP_idxs = []\n",
    "        \n",
    "        for i in range(len(self.y_pred)):\n",
    "            if self.y_pred[i] == 1 and self.y_test[i] != self.y_pred[i]:\n",
    "                self.FP.append(i)\n",
    "        \n",
    "        self.FP_idxs = list(map(lambda x: self.test_scene_idxs[x], self.FP))\n",
    "        \n",
    "        %matplotlib inline\n",
    "        dim = math.floor(math.sqrt(len(self.FP_idxs)))\n",
    "\n",
    "        fig = plt.figure(figsize=(12,12))\n",
    "        ax = [fig.add_subplot(dim, dim, i+1) for i in range(dim**2)]\n",
    "\n",
    "        for idx, a in enumerate(ax):\n",
    "            img = plt.imread(os.path.join('/raid/data/datasets/broden1_384/images/', \n",
    "                                          self.test_dataframe.loc[int(self.FP_idxs[idx]), 'image']))\n",
    "            a.axis('off')\n",
    "            a.imshow(img)\n",
    "\n",
    "        fig.subplots_adjust(wspace=0, hspace=0)\n",
    "        plt.show()\n",
    "        \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('../data/', 'broden_concepts_cavs.pickle'), 'rb') as handle:\n",
    "    broden_concept_accuracy = pickle.load(handle)\n",
    "broden_concepts = list(broden_concept_accuracy.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in broden_concepts:\n",
    "    if broden_concept_accuracy[key]['accuracy'] < 0.75:\n",
    "        del broden_concept_accuracy[key]\n",
    "        \n",
    "broden_concepts = list(broden_concept_accuracy.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the Scenic-Or-Not images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "son_path = '/raid/data/datasets/SoN/'\n",
    "csv_path = '../data/votes.tsv'\n",
    "image_path = son_path + 'images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the csv file and only use the columns with 'ID' and 'Average score'. The image names are equal to the ID + .jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info = pd.read_csv(csv_path, delimiter ='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certain images are to be deleted from the dataset as they are not correctly downloaded. These images are stored in the 'no exist' folder. These images are listed and their IDs are extracted. The image IDs are then linked to the dataframe indices, which are then removed. The index is reset afterwards and the dataframe is stored as .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/guanabana/raid/home/arend036/pim_msc/lib/python3.7/site-packages/pandas/core/indexes/base.py:4291: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  result = getitem(key)\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('../data/updated_votes1.csv'):\n",
    "    updated_votes = pd.read_csv('../data/updated_votes.csv', index_col = 0)\n",
    "    \n",
    "else:\n",
    "    deleted_imgs = [f for f in glob.glob('/raid/data/datasets/SoN/images/no_exist/' + \"*.jpg\", recursive=False)]\n",
    "    deleted_imgs = list(map(lambda x: [int(s) for s in re.findall(r'\\d+', x)][0], deleted_imgs))\n",
    "\n",
    "    remove_indices = tuple(map(lambda x: data_info.loc[data_info.ID == x].index[0], deleted_imgs))\n",
    "\n",
    "    updated_votes = data_info.drop(data_info.index[[remove_indices]])\n",
    "    updated_votes.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    updated_votes.to_csv('../data/updated_votes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Dataset for the Scenic-Or-Not images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "son_dataset = SonDataset('../data/updated_votes.csv', \n",
    "                         image_path, \n",
    "                         transform = transforms.Compose([transforms.Resize(224),\n",
    "                                                         transforms.ToTensor(),\n",
    "                                                         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                              std=[0.229, 0.224, 0.225])\n",
    "                                                        ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run all the SoN images through the model and store the activations in a dictionary. In which the image index in de *updated_votes_df* are the keys and the activation tensors the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('../data/son_tensors.pickle'):\n",
    "    with open('../data/son_tensors.pickle', 'rb') as handle:\n",
    "        son_tensors = pickle.load(handle)\n",
    "        \n",
    "else:\n",
    "    son_idxs = list(range(len(updated_votes)))\n",
    "    son_tensors = MakeVectorDictionary(basenet,\n",
    "                                      out_layer,\n",
    "                                      son_dataset,\n",
    "                                      son_idxs,\n",
    "                                      file_name = 'son_tensors.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 images are not able to get through the model and thus need to be removed from the *updated_votes_df*. The indices of the images are:\n",
    " - 52642\n",
    " - 201047"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_votes.drop([52642, 201047], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each SoN image the probability score for each concept from the Broden dataset is calculated. The probability score is calculated as follows: <br>\n",
    "$CAV_{Broden} * tensor_{image} + bias_{Broden}$\n",
    "\n",
    "The result is stored in a dataframe and written to a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "son_idxs = list(son_tensors.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_score_matrix = np.zeros((len(son_tensors), len(broden_concepts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('../data/concept_scores.csv'):\n",
    "    concept_score_df = pd.read_csv('../data/concept_scores.csv', index_col = 0)\n",
    "else:\n",
    "    for i in tqdm.tqdm_notebook(range(len(son_tensors))):\n",
    "        son_img_activation = son_tensors[son_idxs[i]].numpy()\n",
    "    \n",
    "        for c in range(len(broden_concepts)):\n",
    "            cav = broden_concept_accuracy[broden_concepts[c]]['cav']\n",
    "            bias = broden_concept_accuracy[broden_concepts[c]]['bias']\n",
    "\n",
    "            concept_score = np.dot(cav, son_img_activation) + bias\n",
    "            concept_score_matrix[i][c] = concept_score\n",
    "            \n",
    "    concept_score_df = pd.DataFrame(concept_score_matrix, columns = broden_concepts)\n",
    "    concept_score_df.to_csv('../data/concept_scores.csv')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Kendall's Tau test is applied to check if which concepts correlate with an increase in scenicness. \"Kendall’s tau is a measure of the correspondence between two rankings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenic_score = np.asarray(updated_votes.Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594a8564e0554bd99f9de1f6f954a605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=722), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_concepts = list(concept_score_df.columns)\n",
    "kendall_tau_score = {'tau': [],\n",
    "                    'p_value': []}\n",
    "\n",
    "for concept in tqdm.notebook.tqdm(all_concepts):\n",
    "    concept_score = np.asarray(concept_score_df.loc[:,concept])\n",
    "    tau, p_value = stats.kendalltau(concept_score, scenic_score)\n",
    "    kendall_tau_score['tau'].append(tau)\n",
    "    kendall_tau_score['p_value'].append(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "kendall_tau_df = pd.DataFrame.from_dict(kendall_tau_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "kendall_tau_df['concept'] = all_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau</th>\n",
       "      <th>p_value</th>\n",
       "      <th>concept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.388663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.373547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>street-s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.366121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sidewalk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>-0.360514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>crosswalk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>-0.345220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>parking_lot-s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>-0.325832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>windows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>-0.315826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>parking_garage-indoor-s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>-0.309767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bleachers-outdoor-s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>-0.298709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>platform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.297742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>-0.288954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.288865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>-0.288649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>-0.279350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>baggage_claim-s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>-0.279317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>manufactured_home-s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>-0.278587</td>\n",
       "      <td>0.0</td>\n",
       "      <td>gas_station-s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>-0.271888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>guardhouse-s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>-0.266839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>jail-indoor-s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>-0.266185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>florist_shop-outdoor-s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>-0.264812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>shop window</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tau  p_value                  concept\n",
       "3   -0.388663      0.0                 building\n",
       "26  -0.373547      0.0                 street-s\n",
       "18  -0.366121      0.0                 sidewalk\n",
       "141 -0.360514      0.0                crosswalk\n",
       "346 -0.345220      0.0            parking_lot-s\n",
       "225 -0.325832      0.0                  windows\n",
       "443 -0.315826      0.0  parking_garage-indoor-s\n",
       "548 -0.309767      0.0      bleachers-outdoor-s\n",
       "148 -0.298709      0.0                 platform\n",
       "10  -0.297742      0.0                     road\n",
       "75  -0.288954      0.0                     pane\n",
       "15  -0.288865      0.0                      car\n",
       "86  -0.288649      0.0                    truck\n",
       "415 -0.279350      0.0          baggage_claim-s\n",
       "642 -0.279317      0.0      manufactured_home-s\n",
       "424 -0.278587      0.0            gas_station-s\n",
       "629 -0.271888      0.0             guardhouse-s\n",
       "574 -0.266839      0.0            jail-indoor-s\n",
       "710 -0.266185      0.0   florist_shop-outdoor-s\n",
       "114 -0.264812      0.0              shop window"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kendall_tau_df.sort_values(by=['tau'], ascending=True, inplace = True)\n",
    "kendall_tau_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Average</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Geograph URI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>136</td>\n",
       "      <td>53.3110</td>\n",
       "      <td>-2.532870</td>\n",
       "      <td>2.3000</td>\n",
       "      <td>0.6100</td>\n",
       "      <td>1,2,2,2,4,3,2,3,2,2</td>\n",
       "      <td>http://www.geograph.org.uk/photo/1363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>453</td>\n",
       "      <td>50.7721</td>\n",
       "      <td>-0.798666</td>\n",
       "      <td>2.1429</td>\n",
       "      <td>1.8367</td>\n",
       "      <td>5,3,2,1,2,1,1</td>\n",
       "      <td>http://www.geograph.org.uk/photo/5058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>996</td>\n",
       "      <td>51.2340</td>\n",
       "      <td>-1.296650</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1.2500</td>\n",
       "      <td>1,1,3,1,1,3,2,4</td>\n",
       "      <td>http://www.geograph.org.uk/photo/8856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>2114</td>\n",
       "      <td>54.9949</td>\n",
       "      <td>-1.561670</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1.5000</td>\n",
       "      <td>4,1,1,2</td>\n",
       "      <td>http://www.geograph.org.uk/photo/17043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3256</th>\n",
       "      <td>3319</td>\n",
       "      <td>51.4877</td>\n",
       "      <td>-0.533629</td>\n",
       "      <td>1.7500</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>1,1,2,3</td>\n",
       "      <td>http://www.geograph.org.uk/photo/25757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210801</th>\n",
       "      <td>216341</td>\n",
       "      <td>51.7588</td>\n",
       "      <td>-4.651930</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>3.6875</td>\n",
       "      <td>8,5,9,5,7,5,3,4</td>\n",
       "      <td>http://www.geograph.org.uk/photo/1152924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210855</th>\n",
       "      <td>216398</td>\n",
       "      <td>51.4733</td>\n",
       "      <td>-0.175220</td>\n",
       "      <td>2.1250</td>\n",
       "      <td>1.1094</td>\n",
       "      <td>3,1,1,4,3,2,1,2</td>\n",
       "      <td>http://www.geograph.org.uk/photo/1153170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211551</th>\n",
       "      <td>217104</td>\n",
       "      <td>53.8167</td>\n",
       "      <td>-3.014740</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3,2,1,5,4</td>\n",
       "      <td>http://www.geograph.org.uk/photo/1155767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211643</th>\n",
       "      <td>217198</td>\n",
       "      <td>52.8725</td>\n",
       "      <td>-1.314420</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>2.6667</td>\n",
       "      <td>6,5,6,7,2,4</td>\n",
       "      <td>http://www.geograph.org.uk/photo/1156076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212048</th>\n",
       "      <td>217616</td>\n",
       "      <td>51.5346</td>\n",
       "      <td>-0.127921</td>\n",
       "      <td>3.8750</td>\n",
       "      <td>2.6094</td>\n",
       "      <td>4,7,2,6,3,3,3,3</td>\n",
       "      <td>http://www.geograph.org.uk/photo/1157587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>531 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID      Lat       Lon  Average  Variance                Votes  \\\n",
       "133        136  53.3110 -2.532870   2.3000    0.6100  1,2,2,2,4,3,2,3,2,2   \n",
       "441        453  50.7721 -0.798666   2.1429    1.8367        5,3,2,1,2,1,1   \n",
       "977        996  51.2340 -1.296650   2.0000    1.2500      1,1,3,1,1,3,2,4   \n",
       "2077      2114  54.9949 -1.561670   2.0000    1.5000              4,1,1,2   \n",
       "3256      3319  51.4877 -0.533629   1.7500    0.6875              1,1,2,3   \n",
       "...        ...      ...       ...      ...       ...                  ...   \n",
       "210801  216341  51.7588 -4.651930   5.7500    3.6875      8,5,9,5,7,5,3,4   \n",
       "210855  216398  51.4733 -0.175220   2.1250    1.1094      3,1,1,4,3,2,1,2   \n",
       "211551  217104  53.8167 -3.014740   3.0000    2.0000            3,2,1,5,4   \n",
       "211643  217198  52.8725 -1.314420   5.0000    2.6667          6,5,6,7,2,4   \n",
       "212048  217616  51.5346 -0.127921   3.8750    2.6094      4,7,2,6,3,3,3,3   \n",
       "\n",
       "                                    Geograph URI  \n",
       "133        http://www.geograph.org.uk/photo/1363  \n",
       "441        http://www.geograph.org.uk/photo/5058  \n",
       "977        http://www.geograph.org.uk/photo/8856  \n",
       "2077      http://www.geograph.org.uk/photo/17043  \n",
       "3256      http://www.geograph.org.uk/photo/25757  \n",
       "...                                          ...  \n",
       "210801  http://www.geograph.org.uk/photo/1152924  \n",
       "210855  http://www.geograph.org.uk/photo/1153170  \n",
       "211551  http://www.geograph.org.uk/photo/1155767  \n",
       "211643  http://www.geograph.org.uk/photo/1156076  \n",
       "212048  http://www.geograph.org.uk/photo/1157587  \n",
       "\n",
       "[531 rows x 7 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file = []\n",
    "img_name = updated_votes.loc[5, 'ID'].astype(str)\n",
    "for directory, _ , _ in os.walk('/raid/data/datasets/SoN/images'):\n",
    "    img_file.extend(glob.glob(os.path.join(directory, img_name + '.jpg')))\n",
    "    \n",
    "Image.open(img_file[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3022"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenic_imgs = np.asarray(updated_votes.loc[updated_votes.Average > 80,].index)\n",
    "len(scenic_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept_imgs = list(concept_score_df.loc[concept_score_df['coast-s'] > 1000,].index)\n",
    "concept_df = updated_votes.loc[concept_imgs,]\n",
    "len(concept_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotDot(df):\n",
    "    \n",
    "    folium.Marker(location=[df.Lat, df.Lon],\n",
    "                  popup = df.ID,\n",
    "                  radius=2,\n",
    "                  weight=0).add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,<!DOCTYPE html>
<head>    
    <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
    
        <script>
            L_NO_TOUCH = false;
            L_DISABLE_3D = false;
        </script>
    
    <script src="https://cdn.jsdelivr.net/npm/leaflet@1.5.1/dist/leaflet.js"></script>
    <script src="https://code.jquery.com/jquery-1.12.4.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/leaflet@1.5.1/dist/leaflet.css"/>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css"/>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap-theme.min.css"/>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css"/>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css"/>
    <link rel="stylesheet" href="https://rawcdn.githack.com/python-visualization/folium/master/folium/templates/leaflet.awesome.rotate.css"/>
    <style>html, body {width: 100%;height: 100%;margin: 0;padding: 0;}</style>
    <style>#map {position:absolute;top:0;bottom:0;right:0;left:0;}</style>
    
            <meta name="viewport" content="width=device-width,
                initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
            <style>
                #map_5f0c40a1905a40058a0ac95e5ec154d3 {
                    position: relative;
                    width: 100.0%;
                    height: 100.0%;
                    left: 0.0%;
                    top: 0.0%;
                }
            </style>
        
</head>
<body>    
    
            <div class="folium-map" id="map_5f0c40a1905a40058a0ac95e5ec154d3" ></div>
        
</body>
<script>    
    
            var map_5f0c40a1905a40058a0ac95e5ec154d3 = L.map(
                "map_5f0c40a1905a40058a0ac95e5ec154d3",
                {
                    center: [52.9133, -1.6089],
                    crs: L.CRS.EPSG3857,
                    zoom: 6,
                    zoomControl: true,
                    preferCanvas: false,
                }
            );

            

        
    
            var tile_layer_6c6c55094f3a47f398337c3f8d137e22 = L.tileLayer(
                "https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png",
                {"attribution": "Data by \u0026copy; \u003ca href=\"http://openstreetmap.org\"\u003eOpenStreetMap\u003c/a\u003e, under \u003ca href=\"http://www.openstreetmap.org/copyright\"\u003eODbL\u003c/a\u003e.", "detectRetina": false, "maxNativeZoom": 18, "maxZoom": 18, "minZoom": 0, "noWrap": false, "opacity": 1, "subdomains": "abc", "tms": false}
            ).addTo(map_5f0c40a1905a40058a0ac95e5ec154d3);
        
    
            var marker_132589edabdb431bbf18a76265e7b368 = L.marker(
                [50.16, -4.97831],
                {"radius": 2, "weight": 0}
            ).addTo(map_5f0c40a1905a40058a0ac95e5ec154d3);
        
    
        var popup_0bbbc7d376d247abb788e79259c569e1 = L.popup({"maxWidth": "100%"});

        
            var html_ece2bb2dbfb549b69fb11c8642df5953 = $(`<div id="html_ece2bb2dbfb549b69fb11c8642df5953" style="width: 100.0%; height: 100.0%;">3868</div>`)[0];
            popup_0bbbc7d376d247abb788e79259c569e1.setContent(html_ece2bb2dbfb549b69fb11c8642df5953);
        

        marker_132589edabdb431bbf18a76265e7b368.bindPopup(popup_0bbbc7d376d247abb788e79259c569e1)
        ;

        
    
    
            var marker_aad5ac35b446496c8e7432db484ae300 = L.marker(
                [56.9316, -7.498589999999999],
                {"radius": 2, "weight": 0}
            ).addTo(map_5f0c40a1905a40058a0ac95e5ec154d3);
        
    
        var popup_7bdfa9e806d34dcb8eda847795fe512f = L.popup({"maxWidth": "100%"});

        
            var html_d93610beefcf49d0b6175ad4961ea5d5 = $(`<div id="html_d93610beefcf49d0b6175ad4961ea5d5" style="width: 100.0%; height: 100.0%;">4814</div>`)[0];
            popup_7bdfa9e806d34dcb8eda847795fe512f.setContent(html_d93610beefcf49d0b6175ad4961ea5d5);
        

        marker_aad5ac35b446496c8e7432db484ae300.bindPopup(popup_7bdfa9e806d34dcb8eda847795fe512f)
        ;

        
    
    
            var marker_70604806cf434aa5a5c8baf69608b613 = L.marker(
                [50.1972, -3.71653],
                {"radius": 2, "weight": 0}
            ).addTo(map_5f0c40a1905a40058a0ac95e5ec154d3);
        
    
        var popup_bc01bf06e41d41888cfa1dd2e905cc7f = L.popup({"maxWidth": "100%"});

        
            var html_ff600875bd104195a6bca8cbe4291c39 = $(`<div id="html_ff600875bd104195a6bca8cbe4291c39" style="width: 100.0%; height: 100.0%;">11912</div>`)[0];
            popup_bc01bf06e41d41888cfa1dd2e905cc7f.setContent(html_ff600875bd104195a6bca8cbe4291c39);
        

        marker_70604806cf434aa5a5c8baf69608b613.bindPopup(popup_bc01bf06e41d41888cfa1dd2e905cc7f)
        ;

        
    
    
            var marker_7aec170cfc7c4c1985fda2402b422229 = L.marker(
                [57.6991, -4.03883],
                {"radius": 2, "weight": 0}
            ).addTo(map_5f0c40a1905a40058a0ac95e5ec154d3);
        
    
        var popup_39fbb272edeb49ee85498c90684d8ce2 = L.popup({"maxWidth": "100%"});

        
            var html_320068109e5043a99b4b54dcbcd74768 = $(`<div id="html_320068109e5043a99b4b54dcbcd74768" style="width: 100.0%; height: 100.0%;">24261</div>`)[0];
            popup_39fbb272edeb49ee85498c90684d8ce2.setContent(html_320068109e5043a99b4b54dcbcd74768);
        

        marker_7aec170cfc7c4c1985fda2402b422229.bindPopup(popup_39fbb272edeb49ee85498c90684d8ce2)
        ;

        
    
    
            var marker_ad08ec69c4ca4bcfa0b468428a8f5409 = L.marker(
                [49.8653, -6.40511],
                {"radius": 2, "weight": 0}
            ).addTo(map_5f0c40a1905a40058a0ac95e5ec154d3);
        
    
        var popup_ddebe32f0013458890fcf6c5aa97c76d = L.popup({"maxWidth": "100%"});

        
            var html_4ef30a72803f4f32b94fe2ab79059d78 = $(`<div id="html_4ef30a72803f4f32b94fe2ab79059d78" style="width: 100.0%; height: 100.0%;">44706</div>`)[0];
            popup_ddebe32f0013458890fcf6c5aa97c76d.setContent(html_4ef30a72803f4f32b94fe2ab79059d78);
        

        marker_ad08ec69c4ca4bcfa0b468428a8f5409.bindPopup(popup_ddebe32f0013458890fcf6c5aa97c76d)
        ;

        
    
    
            var marker_dc2cbe5020894c22830f70123fa4cb8d = L.marker(
                [58.0437, -4.42174],
                {"radius": 2, "weight": 0}
            ).addTo(map_5f0c40a1905a40058a0ac95e5ec154d3);
        
    
        var popup_697c661b6e7f428aaae9ae4586cc300c = L.popup({"maxWidth": "100%"});

        
            var html_9cf319aab68d4767a16b7386daf324b4 = $(`<div id="html_9cf319aab68d4767a16b7386daf324b4" style="width: 100.0%; height: 100.0%;">64670</div>`)[0];
            popup_697c661b6e7f428aaae9ae4586cc300c.setContent(html_9cf319aab68d4767a16b7386daf324b4);
        

        marker_dc2cbe5020894c22830f70123fa4cb8d.bindPopup(popup_697c661b6e7f428aaae9ae4586cc300c)
        ;

        
    
    
            var marker_c02ceb41a7b84e7a864438369939a812 = L.marker(
                [50.705, -1.56746],
                {"radius": 2, "weight": 0}
            ).addTo(map_5f0c40a1905a40058a0ac95e5ec154d3);
        
    
        var popup_7d5f426c09864d0cb627c96adcb7d558 = L.popup({"maxWidth": "100%"});

        
            var html_694bcf7320b54577892f11dbad4711b5 = $(`<div id="html_694bcf7320b54577892f11dbad4711b5" style="width: 100.0%; height: 100.0%;">68502</div>`)[0];
            popup_7d5f426c09864d0cb627c96adcb7d558.setContent(html_694bcf7320b54577892f11dbad4711b5);
        

        marker_c02ceb41a7b84e7a864438369939a812.bindPopup(popup_7d5f426c09864d0cb627c96adcb7d558)
        ;

        
    
    
            var marker_07367874a98647e4ad3e0bb6ba8c4a7f = L.marker(
                [52.3243, 1.16622],
                {"radius": 2, "weight": 0}
            ).addTo(map_5f0c40a1905a40058a0ac95e5ec154d3);
        
    
        var popup_a6972d07b9774b7e8996b1486e984efa = L.popup({"maxWidth": "100%"});

        
            var html_482e173b87414a1eb75a76e19b2a04ac = $(`<div id="html_482e173b87414a1eb75a76e19b2a04ac" style="width: 100.0%; height: 100.0%;">70116</div>`)[0];
            popup_a6972d07b9774b7e8996b1486e984efa.setContent(html_482e173b87414a1eb75a76e19b2a04ac);
        

        marker_07367874a98647e4ad3e0bb6ba8c4a7f.bindPopup(popup_a6972d07b9774b7e8996b1486e984efa)
        ;

        
    
    
            var marker_46d9d406890a42ce92577325820952c4 = L.marker(
                [55.5287, -1.61057],
                {"radius": 2, "weight": 0}
            ).addTo(map_5f0c40a1905a40058a0ac95e5ec154d3);
        
    
        var popup_a1c60d750cb64eea8a1690825c7abced = L.popup({"maxWidth": "100%"});

        
            var html_1898d95cd9da4813965756629f7c35a0 = $(`<div id="html_1898d95cd9da4813965756629f7c35a0" style="width: 100.0%; height: 100.0%;">87015</div>`)[0];
            popup_a1c60d750cb64eea8a1690825c7abced.setContent(html_1898d95cd9da4813965756629f7c35a0);
        

        marker_46d9d406890a42ce92577325820952c4.bindPopup(popup_a1c60d750cb64eea8a1690825c7abced)
        ;

        
    
    
            var marker_e8e94753e98c45b2af1300f39b77276c = L.marker(
                [52.1006, -1.1301700000000001],
                {"radius": 2, "weight": 0}
            ).addTo(map_5f0c40a1905a40058a0ac95e5ec154d3);
        
    
        var popup_9ab7b3acf8824033b34ccd276122094d = L.popup({"maxWidth": "100%"});

        
            var html_3e34254b89534a5db11d51d7640b985e = $(`<div id="html_3e34254b89534a5db11d51d7640b985e" style="width: 100.0%; height: 100.0%;">90950</div>`)[0];
            popup_9ab7b3acf8824033b34ccd276122094d.setContent(html_3e34254b89534a5db11d51d7640b985e);
        

        marker_e8e94753e98c45b2af1300f39b77276c.bindPopup(popup_9ab7b3acf8824033b34ccd276122094d)
        ;

        
    
    
            var marker_ddd56622862a4ee2857a21c58e7b4ac0 = L.marker(
                [52.3613, -2.46732],
                {"radius": 2, "weight": 0}
            ).addTo(map_5f0c40a1905a40058a0ac95e5ec154d3);
        
    
        var popup_65c3e1f7b16746159e032e3c679cbe60 = L.popup({"maxWidth": "100%"});

        
            var html_dbada954056344419805952dec2e3909 = $(`<div id="html_dbada954056344419805952dec2e3909" style="width: 100.0%; height: 100.0%;">93935</div>`)[0];
            popup_65c3e1f7b16746159e032e3c679cbe60.setContent(html_dbada954056344419805952dec2e3909);
        

        marker_ddd56622862a4ee2857a21c58e7b4ac0.bindPopup(popup_65c3e1f7b16746159e032e3c679cbe60)
        ;

        
    
    
            var marker_4405edd870ac40aa960a30a30503e1e1 = L.marker(
                [58.232, -6.17922],
                {"radius": 2, "weight": 0}
            ).addTo(map_5f0c40a1905a40058a0ac95e5ec154d3);
        
    
        var popup_b3899d7a4c8b4ceda506f337530634b7 = L.popup({"maxWidth": "100%"});

        
            var html_b20a20279d78454a867103f7f9dded3e = $(`<div id="html_b20a20279d78454a867103f7f9dded3e" style="width: 100.0%; height: 100.0%;">100639</div>`)[0];
            popup_b3899d7a4c8b4ceda506f337530634b7.setContent(html_b20a20279d78454a867103f7f9dded3e);
        

        marker_4405edd870ac40aa960a30a30503e1e1.bindPopup(popup_b3899d7a4c8b4ceda506f337530634b7)
        ;

        
    
    
            var marker_704d49afc5614a4a85628fa90a83dce8 = L.marker(
                [58.0052, -4.5136],
                {"radius": 2, "weight": 0}
            ).addTo(map_5f0c40a1905a40058a0ac95e5ec154d3);
        
    
        var popup_a3a14ce74ec3466095404e6f0afc6824 = L.popup({"maxWidth": "100%"});

        
            var html_cbf7fc3955824ae1847056f639eedff6 = $(`<div id="html_cbf7fc3955824ae1847056f639eedff6" style="width: 100.0%; height: 100.0%;">105595</div>`)[0];
            popup_a3a14ce74ec3466095404e6f0afc6824.setContent(html_cbf7fc3955824ae1847056f639eedff6);
        

        marker_704d49afc5614a4a85628fa90a83dce8.bindPopup(popup_a3a14ce74ec3466095404e6f0afc6824)
        ;

        
    
    
            var marker_e8167ce57f324ec4a2d332f14cd8c2d3 = L.marker(
                [60.7574, -0.80291],
                {"radius": 2, "weight": 0}
            ).addTo(map_5f0c40a1905a40058a0ac95e5ec154d3);
        
    
        var popup_bc7f32ceac0a4dcc86fafdc24d2c7170 = L.popup({"maxWidth": "100%"});

        
            var html_2251b3c15f4f414c9aa50dfccc077137 = $(`<div id="html_2251b3c15f4f414c9aa50dfccc077137" style="width: 100.0%; height: 100.0%;">111434</div>`)[0];
            popup_bc7f32ceac0a4dcc86fafdc24d2c7170.setContent(html_2251b3c15f4f414c9aa50dfccc077137);
        

        marker_e8167ce57f324ec4a2d332f14cd8c2d3.bindPopup(popup_bc7f32ceac0a4dcc86fafdc24d2c7170)
        ;

        
    
    
            var marker_5dc2c2f90bf74bda9960927c5197f276 = L.marker(
                [51.233000000000004, -0.626262],
                {"radius": 2, "weight": 0}
            ).addTo(map_5f0c40a1905a40058a0ac95e5ec154d3);
        
    
        var popup_e247ad6dc32e4e5db9bb2c47242bd85f = L.popup({"maxWidth": "100%"});

        
            var html_ae9cca37f3cc44339f94782a8a1f7d4c = $(`<div id="html_ae9cca37f3cc44339f94782a8a1f7d4c" style="width: 100.0%; height: 100.0%;">118655</div>`)[0];
            popup_e247ad6dc32e4e5db9bb2c47242bd85f.setContent(html_ae9cca37f3cc44339f94782a8a1f7d4c);
        

        marker_5dc2c2f90bf74bda9960927c5197f276.bindPopup(popup_e247ad6dc32e4e5db9bb2c47242bd85f)
        ;

        
    
    
            var marker_9c8f3eee260546818bb72888ade7c49b = L.marker(
                [51.7687, -5.1283199999999995],
                {"radius": 2, "weight": 0}
            ).addTo(map_5f0c40a1905a40058a0ac95e5ec154d3);
        
    
        var popup_5804ad5a1c6d4338b53c7174a3680808 = L.popup({"maxWidth": "100%"});

        
            var html_f09c0739f0934ace88c154c28f2a25d7 = $(`<div id="html_f09c0739f0934ace88c154c28f2a25d7" style="width: 100.0%; height: 100.0%;">121433</div>`)[0];
            popup_5804ad5a1c6d4338b53c7174a3680808.setContent(html_f09c0739f0934ace88c154c28f2a25d7);
        

        marker_9c8f3eee260546818bb72888ade7c49b.bindPopup(popup_5804ad5a1c6d4338b53c7174a3680808)
        ;

        
    
    
            var marker_254ef1aa7da14ca682ee3f7d913803fd = L.marker(
                [56.3724, -4.60961],
                {"radius": 2, "weight": 0}
            ).addTo(map_5f0c40a1905a40058a0ac95e5ec154d3);
        
    
        var popup_cadf23f36a844ec8a34ce26162072f35 = L.popup({"maxWidth": "100%"});

        
            var html_74b5e67194b04cf0808a510b86071b09 = $(`<div id="html_74b5e67194b04cf0808a510b86071b09" style="width: 100.0%; height: 100.0%;">142510</div>`)[0];
            popup_cadf23f36a844ec8a34ce26162072f35.setContent(html_74b5e67194b04cf0808a510b86071b09);
        

        marker_254ef1aa7da14ca682ee3f7d913803fd.bindPopup(popup_cadf23f36a844ec8a34ce26162072f35)
        ;

        
    
    
            var marker_f496b99c9b5b41338f470ff4087f6ebc = L.marker(
                [54.2492, -4.488919999999999],
                {"radius": 2, "weight": 0}
            ).addTo(map_5f0c40a1905a40058a0ac95e5ec154d3);
        
    
        var popup_51b6c567726241dcac7ce9d6946af0bc = L.popup({"maxWidth": "100%"});

        
            var html_acd1df30ab6543508717d5916edadb02 = $(`<div id="html_acd1df30ab6543508717d5916edadb02" style="width: 100.0%; height: 100.0%;">144633</div>`)[0];
            popup_51b6c567726241dcac7ce9d6946af0bc.setContent(html_acd1df30ab6543508717d5916edadb02);
        

        marker_f496b99c9b5b41338f470ff4087f6ebc.bindPopup(popup_51b6c567726241dcac7ce9d6946af0bc)
        ;

        
    
    
            var marker_5b522a7c330543949397ffc4b745d137 = L.marker(
                [53.6151, -1.42415],
                {"radius": 2, "weight": 0}
            ).addTo(map_5f0c40a1905a40058a0ac95e5ec154d3);
        
    
        var popup_bc6794d113f941a08b3df92aca12ed86 = L.popup({"maxWidth": "100%"});

        
            var html_ed19b8c5d25f4a5aa46d72fb745ce436 = $(`<div id="html_ed19b8c5d25f4a5aa46d72fb745ce436" style="width: 100.0%; height: 100.0%;">151065</div>`)[0];
            popup_bc6794d113f941a08b3df92aca12ed86.setContent(html_ed19b8c5d25f4a5aa46d72fb745ce436);
        

        marker_5b522a7c330543949397ffc4b745d137.bindPopup(popup_bc6794d113f941a08b3df92aca12ed86)
        ;

        
    
    
            var marker_e6d601018e0e4cc4ba3c7a43f49a415a = L.marker(
                [57.3818, -5.8278],
                {"radius": 2, "weight": 0}
            ).addTo(map_5f0c40a1905a40058a0ac95e5ec154d3);
        
    
        var popup_72a05f0448b040ef8500e8d362675a62 = L.popup({"maxWidth": "100%"});

        
            var html_197e0b4af97b45c4b51d2174558ec9e0 = $(`<div id="html_197e0b4af97b45c4b51d2174558ec9e0" style="width: 100.0%; height: 100.0%;">151612</div>`)[0];
            popup_72a05f0448b040ef8500e8d362675a62.setContent(html_197e0b4af97b45c4b51d2174558ec9e0);
        

        marker_e6d601018e0e4cc4ba3c7a43f49a415a.bindPopup(popup_72a05f0448b040ef8500e8d362675a62)
        ;

        
    
    
            var marker_0cd89a300b2646c18c90294cad0ed846 = L.marker(
                [55.2614, -1.94807],
                {"radius": 2, "weight": 0}
            ).addTo(map_5f0c40a1905a40058a0ac95e5ec154d3);
        
    
        var popup_b696e5a5a727490c9eaf7ab25cb74f20 = L.popup({"maxWidth": "100%"});

        
            var html_553fc3e0b78544d6a559da3d7df56956 = $(`<div id="html_553fc3e0b78544d6a559da3d7df56956" style="width: 100.0%; height: 100.0%;">159136</div>`)[0];
            popup_b696e5a5a727490c9eaf7ab25cb74f20.setContent(html_553fc3e0b78544d6a559da3d7df56956);
        

        marker_0cd89a300b2646c18c90294cad0ed846.bindPopup(popup_b696e5a5a727490c9eaf7ab25cb74f20)
        ;

        
    
    
            var marker_486b2079d5de413aa94d4f514d4c5a0d = L.marker(
                [55.5794, -4.63782],
                {"radius": 2, "weight": 0}
            ).addTo(map_5f0c40a1905a40058a0ac95e5ec154d3);
        
    
        var popup_fbe413b56a914566ba79fe60eb3b3520 = L.popup({"maxWidth": "100%"});

        
            var html_ce907b11b4b74cb399ab9397a995467b = $(`<div id="html_ce907b11b4b74cb399ab9397a995467b" style="width: 100.0%; height: 100.0%;">159146</div>`)[0];
            popup_fbe413b56a914566ba79fe60eb3b3520.setContent(html_ce907b11b4b74cb399ab9397a995467b);
        

        marker_486b2079d5de413aa94d4f514d4c5a0d.bindPopup(popup_fbe413b56a914566ba79fe60eb3b3520)
        ;

        
    
    
            var marker_68ee480938ca4937b529a7df173e89be = L.marker(
                [56.8554, -4.52159],
                {"radius": 2, "weight": 0}
            ).addTo(map_5f0c40a1905a40058a0ac95e5ec154d3);
        
    
        var popup_d2e83e4ab38f4295b002ac37048864f2 = L.popup({"maxWidth": "100%"});

        
            var html_bd72d745f4164c339f89af9270ef5c20 = $(`<div id="html_bd72d745f4164c339f89af9270ef5c20" style="width: 100.0%; height: 100.0%;">159201</div>`)[0];
            popup_d2e83e4ab38f4295b002ac37048864f2.setContent(html_bd72d745f4164c339f89af9270ef5c20);
        

        marker_68ee480938ca4937b529a7df173e89be.bindPopup(popup_d2e83e4ab38f4295b002ac37048864f2)
        ;

        
    
    
            var marker_09d337330e63474f9c409d356c24f1e1 = L.marker(
                [60.7715, -0.9468840000000001],
                {"radius": 2, "weight": 0}
            ).addTo(map_5f0c40a1905a40058a0ac95e5ec154d3);
        
    
        var popup_14d8d9c7a95a4e5aa1c55daccb5b71f3 = L.popup({"maxWidth": "100%"});

        
            var html_3778c5e36fd04c5ba835d8b2498cf40c = $(`<div id="html_3778c5e36fd04c5ba835d8b2498cf40c" style="width: 100.0%; height: 100.0%;">159209</div>`)[0];
            popup_14d8d9c7a95a4e5aa1c55daccb5b71f3.setContent(html_3778c5e36fd04c5ba835d8b2498cf40c);
        

        marker_09d337330e63474f9c409d356c24f1e1.bindPopup(popup_14d8d9c7a95a4e5aa1c55daccb5b71f3)
        ;

        
    
    
            var marker_767448788e5641fd9c112f9837c4804b = L.marker(
                [50.4973, -3.7935300000000005],
                {"radius": 2, "weight": 0}
            ).addTo(map_5f0c40a1905a40058a0ac95e5ec154d3);
        
    
        var popup_8c67f3d1eb04496aaa58be5efb66714c = L.popup({"maxWidth": "100%"});

        
            var html_98ff102d5bd64a2bb85a371353c0db9d = $(`<div id="html_98ff102d5bd64a2bb85a371353c0db9d" style="width: 100.0%; height: 100.0%;">194281</div>`)[0];
            popup_8c67f3d1eb04496aaa58be5efb66714c.setContent(html_98ff102d5bd64a2bb85a371353c0db9d);
        

        marker_767448788e5641fd9c112f9837c4804b.bindPopup(popup_8c67f3d1eb04496aaa58be5efb66714c)
        ;

        
    
    
            var marker_f7db456d7347431a96db093194f1a828 = L.marker(
                [52.3132, -1.45249],
                {"radius": 2, "weight": 0}
            ).addTo(map_5f0c40a1905a40058a0ac95e5ec154d3);
        
    
        var popup_d64d4fff3e7a462fb9a8c029bf28df13 = L.popup({"maxWidth": "100%"});

        
            var html_5574a0144b804134a739bf18f5536be0 = $(`<div id="html_5574a0144b804134a739bf18f5536be0" style="width: 100.0%; height: 100.0%;">200408</div>`)[0];
            popup_d64d4fff3e7a462fb9a8c029bf28df13.setContent(html_5574a0144b804134a739bf18f5536be0);
        

        marker_f7db456d7347431a96db093194f1a828.bindPopup(popup_d64d4fff3e7a462fb9a8c029bf28df13)
        ;

        
    
    
            var marker_3b96f2109f77433caf03ac58837ec32e = L.marker(
                [50.2996, -4.79488],
                {"radius": 2, "weight": 0}
            ).addTo(map_5f0c40a1905a40058a0ac95e5ec154d3);
        
    
        var popup_8ad4542eff4d493db1feb12bcb2abb69 = L.popup({"maxWidth": "100%"});

        
            var html_f8a4eea9349445e1a0e817bd368d0fef = $(`<div id="html_f8a4eea9349445e1a0e817bd368d0fef" style="width: 100.0%; height: 100.0%;">202745</div>`)[0];
            popup_8ad4542eff4d493db1feb12bcb2abb69.setContent(html_f8a4eea9349445e1a0e817bd368d0fef);
        

        marker_3b96f2109f77433caf03ac58837ec32e.bindPopup(popup_8ad4542eff4d493db1feb12bcb2abb69)
        ;

        
    
</script>\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7f033135e110>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = folium.Map(location= [52.9133, -1.6089],\n",
    "              zoom_start = 6)\n",
    "\n",
    "concept_df.apply(PlotDot, axis=1)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_votes = pd.read_csv('../data/votes.tsv', delimiter ='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Average</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Geograph URI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>51.7026</td>\n",
       "      <td>-2.20985</td>\n",
       "      <td>4.1111</td>\n",
       "      <td>1.8765</td>\n",
       "      <td>4,5,3,5,1,4,4,5,6</td>\n",
       "      <td>http://www.geograph.org.uk/photo/7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>51.7026</td>\n",
       "      <td>-2.19538</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>4,4,3,5,4,3,5,4</td>\n",
       "      <td>http://www.geograph.org.uk/photo/8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>51.7116</td>\n",
       "      <td>-2.18094</td>\n",
       "      <td>4.2222</td>\n",
       "      <td>2.1728</td>\n",
       "      <td>5,4,6,5,3,4,1,4,6</td>\n",
       "      <td>http://www.geograph.org.uk/photo/11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>53.3110</td>\n",
       "      <td>-2.51786</td>\n",
       "      <td>3.8000</td>\n",
       "      <td>7.7600</td>\n",
       "      <td>2,4,1,9,3</td>\n",
       "      <td>http://www.geograph.org.uk/photo/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>53.3021</td>\n",
       "      <td>-2.50274</td>\n",
       "      <td>4.1667</td>\n",
       "      <td>3.4722</td>\n",
       "      <td>8,4,2,4,3,4</td>\n",
       "      <td>http://www.geograph.org.uk/photo/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>54.1311</td>\n",
       "      <td>-4.50266</td>\n",
       "      <td>7.5000</td>\n",
       "      <td>2.7500</td>\n",
       "      <td>5,7,9,9</td>\n",
       "      <td>http://www.geograph.org.uk/photo/30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>54.1491</td>\n",
       "      <td>-4.50374</td>\n",
       "      <td>5.1250</td>\n",
       "      <td>3.8594</td>\n",
       "      <td>4,7,5,7,8,5,3,2</td>\n",
       "      <td>http://www.geograph.org.uk/photo/31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>54.2764</td>\n",
       "      <td>-4.43464</td>\n",
       "      <td>8.5000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>6,10,10,10,10,6,7,9</td>\n",
       "      <td>http://www.geograph.org.uk/photo/35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>54.2857</td>\n",
       "      <td>-4.41982</td>\n",
       "      <td>6.5714</td>\n",
       "      <td>3.3878</td>\n",
       "      <td>8,3,8,5,8,6,8</td>\n",
       "      <td>http://www.geograph.org.uk/photo/36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>54.2860</td>\n",
       "      <td>-4.40447</td>\n",
       "      <td>7.2857</td>\n",
       "      <td>8.4898</td>\n",
       "      <td>9,10,4,10,5,3,10</td>\n",
       "      <td>http://www.geograph.org.uk/photo/38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID      Lat      Lon  Average  Variance                Votes  \\\n",
       "0   1  51.7026 -2.20985   4.1111    1.8765    4,5,3,5,1,4,4,5,6   \n",
       "1   2  51.7026 -2.19538   4.0000    0.5000      4,4,3,5,4,3,5,4   \n",
       "2   3  51.7116 -2.18094   4.2222    2.1728    5,4,6,5,3,4,1,4,6   \n",
       "3   4  53.3110 -2.51786   3.8000    7.7600            2,4,1,9,3   \n",
       "4   5  53.3021 -2.50274   4.1667    3.4722          8,4,2,4,3,4   \n",
       "5   6  54.1311 -4.50266   7.5000    2.7500              5,7,9,9   \n",
       "6   7  54.1491 -4.50374   5.1250    3.8594      4,7,5,7,8,5,3,2   \n",
       "7   8  54.2764 -4.43464   8.5000    3.0000  6,10,10,10,10,6,7,9   \n",
       "8   9  54.2857 -4.41982   6.5714    3.3878        8,3,8,5,8,6,8   \n",
       "9  10  54.2860 -4.40447   7.2857    8.4898     9,10,4,10,5,3,10   \n",
       "\n",
       "                          Geograph URI  \n",
       "0   http://www.geograph.org.uk/photo/7  \n",
       "1   http://www.geograph.org.uk/photo/8  \n",
       "2  http://www.geograph.org.uk/photo/11  \n",
       "3  http://www.geograph.org.uk/photo/20  \n",
       "4  http://www.geograph.org.uk/photo/22  \n",
       "5  http://www.geograph.org.uk/photo/30  \n",
       "6  http://www.geograph.org.uk/photo/31  \n",
       "7  http://www.geograph.org.uk/photo/35  \n",
       "8  http://www.geograph.org.uk/photo/36  \n",
       "9  http://www.geograph.org.uk/photo/38  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_votes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
