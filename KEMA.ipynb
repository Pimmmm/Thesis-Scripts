{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg, sparse, stats\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def kernel_manifold_alignment(data1, data2, mu, lanbda, n_neighbors, n_eigs, n_correspondence):\n",
    "    \"\"\"\n",
    "    Aligns the manifolds of two datasets (d x n matrix), where d equals the number of dimensions and \n",
    "    n equals the amount of samples.\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    data1: column matrix (n_features x n_samples)\n",
    "    data2: column matrix (n_features x n_samples)\n",
    "    mu: float (0-1)\n",
    "    lanbda: float (0-1)\n",
    "    n_neighbors: the amount of neighbours to use when determining the topology Laplacian (integer)\n",
    "    n_eigs: the number of dimensions of the latent feature space (integer)\n",
    "    n_correpspondence: the number of datapoints having a correspondence in both datasets (integer)\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    Phi1TtoF: column matrix of data1 transformed to the latent feature space (n_eigs, n_samples)\n",
    "    Phi2TtoF: column matrix of data2 transformed to the latent feature space (n_eigs, n_samples)\n",
    "    ALPHA: eigenvectors\n",
    "    LAMBDA: eigenvalues\n",
    "    \"\"\"\n",
    "    \n",
    "    d1, n1 = data1.shape\n",
    "    d2, n2 = data2.shape\n",
    "    \n",
    "    tot_samples = n1 + n2\n",
    "    \n",
    "    # build topography Laplacian\n",
    "    print('Computing neighbours')\n",
    "    x1_graph = np.zeros((n1, n1))\n",
    "    for n in trange(n1):\n",
    "        x1_nn = cosine_similarity(data1.T, data1.T[n].reshape(1,-1))\n",
    "        x1_nn_ixs = x1_nn.argsort(axis=0)[::-1][1:n_neighbors+1].flatten()\n",
    "        x1_graph[n,x1_nn_ixs] = 1\n",
    "        \n",
    "    x2_graph = np.zeros((n2, n2))\n",
    "    for c in trange(n2):\n",
    "        x2_nn = cosine_similarity(data2.T, data2.T[c].reshape(1,-1))\n",
    "        x2_nn_ixs = x2_nn.argsort(axis=0)[::-1][1:n_neighbors+1].flatten()\n",
    "        x2_graph[c, x2_nn_ixs] = 1\n",
    "    \n",
    "    print(\"Building graph Laplacians\")\n",
    "    #topology matrix\n",
    "    W = linalg.block_diag(x1_graph, x2_graph)\n",
    "    W = (W + W.T)/2\n",
    "    \n",
    "    # similarity matrix\n",
    "    Ws = np.zeros((tot_samples, tot_samples))\n",
    "\n",
    "    Ws1 = np.eye(n1)\n",
    "    Ws2 = np.eye(n2)\n",
    "    Ws3 = np.eye(n_correspondence)\n",
    "\n",
    "    Ws[:n1, :n1] = Ws1\n",
    "    Ws[n1:, n1:] = Ws2\n",
    "    Ws[n1:(n1+n_correspondence), :n_correspondence] = Ws3\n",
    "    Ws[:n_correspondence, n1:(n1+n_correspondence)] = Ws3\n",
    "\n",
    "    Ws = Ws + np.eye(tot_samples)\n",
    "    \n",
    "    #dissimilarity matrix\n",
    "    Wd = np.ones((tot_samples, tot_samples))\n",
    "    np.fill_diagonal(Wd, 0)\n",
    "\n",
    "    Wd1 = np.ones((n_correspondence, n_correspondence))\n",
    "    np.fill_diagonal(Wd1, 0)\n",
    "\n",
    "    Wd[:n_correspondence, n1:(n1+n_correspondence)] = Wd1\n",
    "    Wd[n1:(n1+n_correspondence), :n_correspondence] = Wd1\n",
    "\n",
    "    Wd = Wd + np.eye(Wd.shape[0])\n",
    "    \n",
    "    #normalize the (dis)similarity matrices\n",
    "    Sws = sum(sum(Ws))\n",
    "    Swd = sum(sum(Wd))\n",
    "    Sw = sum(sum(W))\n",
    "\n",
    "    Ws = Ws / Sws * Sw\n",
    "    Wd = Wd / Swd * Sw\n",
    "    \n",
    "    #extract diagonals from the matrices\n",
    "    Dd = np.diag(np.sum(Wd, axis=1))\n",
    "    Ds = np.diag(np.sum(Ws, axis = 1))\n",
    "    D = np.diag(np.sum(W, axis=1))\n",
    "    \n",
    "    #build Laplacians\n",
    "    Ls = Ds - Ws # graph Laplacian of similarity \n",
    "    Ld = Dd - Wd # Laplacian of dissimilarity\n",
    "    L = D - W # Laplacian topology/geometry\n",
    "    \n",
    "    #tweak the algorithm\n",
    "    A = ((1 - mu) * L + mu * Ls) + lanbda * np.eye(Ls.shape[0])\n",
    "    B = Ld\n",
    "    \n",
    "    #compute kernels\n",
    "    kernel_data1 = np.matmul(data1.T, data1)\n",
    "    kernel_data2 = np.matmul(data2.T, data2)\n",
    "    \n",
    "    K = linalg.block_diag(kernel_data1, kernel_data2)\n",
    "    \n",
    "    KA = np.matmul(K,A)\n",
    "    KB = np.matmul(K,B)\n",
    "    KAK = np.matmul(KA, K)\n",
    "    KBK = np.matmul(KB, K)\n",
    "    \n",
    "    print(\"Solving generalized eigenvalue decomposition\")\n",
    "    #determine matrix rank\n",
    "    rank_A = np.linalg.matrix_rank(KAK)\n",
    "    rank_B = np.linalg.matrix_rank(KBK)\n",
    "    \n",
    "    ALPHA, LAMBDA,n_eig = gen_eig(KAK, KBK, 'LM', n_eigs, rank_A, rank_B)\n",
    "    \n",
    "    print(\"Rotating axis if needed\")\n",
    "    lambda_idxs = np.diag(LAMBDA).argsort()\n",
    "    LAMBDA = np.sort(np.diag(LAMBDA))\n",
    "    LAMBDA = LAMBDA.reshape(LAMBDA.shape[0],1)\n",
    "    \n",
    "    ALPHA = ALPHA[:, lambda_idxs]\n",
    "    \n",
    "    E1 = ALPHA[:n1, :] #eigenvectors for the first dataset (CAV)\n",
    "    E2 = ALPHA[n1:, :] #eigenvectors for the second dataset (GloVe)\n",
    "    \n",
    "    #Compare the rotated axis with the 'normal' axis\n",
    "    sourceXpInv = (-1 * np.matmul(E1.T, kernel_data1)).T\n",
    "    sourceXp = np.matmul(E1.T, kernel_data1).T\n",
    "    targetXp = np.matmul(E2.T, kernel_data2).T\n",
    "    \n",
    "    sourceXpInv = stats.zscore(sourceXpInv)\n",
    "    sourceXp = stats.zscore(sourceXp)\n",
    "    targetXp = stats.zscore(targetXp)\n",
    "    \n",
    "    ErrRec = np.zeros((n1, ALPHA.shape[1]))\n",
    "    ErrRecInv = np.zeros((n1, ALPHA.shape[1]))\n",
    "    \n",
    "    m1 = np.zeros((n1, ALPHA.shape[1]))\n",
    "    m1inv = np.zeros((n1, ALPHA.shape[1]))\n",
    "    m2 = np.zeros((n1, ALPHA.shape[1]))\n",
    "    \n",
    "    for j in range(ALPHA.shape[1]):\n",
    "        for i in range(n1):\n",
    "            m1inv[i,j] = np.mean(sourceXpInv[i, j])\n",
    "            m1[i,j] = np.mean(sourceXp[i, j])\n",
    "            m2[i,j] = np.mean(targetXp[i, j])\n",
    "\n",
    "            ErrRec[i,j] = np.square(np.power(np.mean(sourceXp[i, j]) - np.mean(targetXp[i, j]), 2))\n",
    "\n",
    "            ErrRecInv[i,j] = np.square(np.power(np.mean(sourceXpInv[i, j]) - np.mean(targetXp[i, j]),2))\n",
    "            \n",
    "    Sc = ErrRec.max(axis=0) > ErrRecInv.max(axis=0)\n",
    "    \n",
    "    print(\"Inverting axis\")\n",
    "    \n",
    "    ALPHA[:n1, Sc] = ALPHA[:n1, Sc] * -1\n",
    "    \n",
    "    Nf = 100\n",
    "    nVectLin = min(Nf, rank_B)\n",
    "    nVectLin = min(nVectLin, rank_A)\n",
    "    \n",
    "    T1 = n1\n",
    "    T2 = n1\n",
    "    \n",
    "    print(\"Transforming data to the common feature space\")\n",
    "    for Nf in range(nVectLin):\n",
    "        E1 = ALPHA[:n1, :Nf+1]\n",
    "        E2 = ALPHA[n1:, :Nf+1]\n",
    "\n",
    "        Phi1toF = np.matmul(E1.T, kernel_data1)\n",
    "        Phi2toF = np.matmul(E2.T, kernel_data2)\n",
    "\n",
    "        Phi1TtoF = np.matmul(E1.T, kernel_data1) \n",
    "        Phi2TtoF = np.matmul(E2.T, kernel_data2) \n",
    "\n",
    "        m1 = np.mean(Phi1toF.T, axis = 0)\n",
    "        m2 = np.mean(Phi2toF.T, axis = 0)\n",
    "        s1 = np.std(Phi1toF.T, axis = 0)\n",
    "        s2 = np.std(Phi2toF.T, axis =0)\n",
    "\n",
    "        Phi1TtoF = np.divide((Phi1TtoF.T - np.matlib.repmat(m1, T1, 1)), \n",
    "                             np.matlib.repmat(s1, T1, 1)).T\n",
    "\n",
    "        Phi2TtoF = np.divide((Phi2TtoF.T - np.matlib.repmat(m2, T2 ,1)),\n",
    "                             np.matlib.repmat(s2, T2, 1)).T\n",
    "        \n",
    "    return Phi1TtoF, Phi2TtoF, ALPHA, LAMBDA\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_eig(A, B, option, n_eig, rankA, rankB):\n",
    "    \"\"\"\n",
    "    Extracts generalized eigenvalues for problem A * U = B * U * landa\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    n_eig = min(n_eig, rankA, rankB)\n",
    "    \n",
    "    B = (B + B.T) / 2\n",
    "    R = B.shape[0]\n",
    "    rango = rankB\n",
    "    \n",
    "    if rango == R:\n",
    "        U = np.zeros((R, n_eig))\n",
    "        D = np.zeros((n_eig, n_eig))\n",
    "        inv_B = np.linalg.inv(B)\n",
    "        for k in tqdm(range(n_eig)):\n",
    "            d, a = sparse.linalg.eigs(np.matmul(inv_B, A),1, which=option) #'a' are the eigenvectors in the matlab code\n",
    "            d = d.real\n",
    "            a = a.real\n",
    "            \n",
    "            ab = np.matmul(a.T, B)\n",
    "            a = np.divide(a, np.sqrt(np.matmul(ab, a)))\n",
    "            U[:,k] = a.flatten()\n",
    "            D[k,k] = d\n",
    "            \n",
    "            ba = np.matmul(B, a)\n",
    "            aTb = np.matmul(a.T, B)\n",
    "            dba = d * ba\n",
    "            A = A - np.matmul(dba, aTb)\n",
    "        \n",
    "        return U, D, n_eig\n",
    "    \n",
    "    else:\n",
    "        print('Calculating d and v')\n",
    "        d, v = sparse.linalg.eigs(B, rango)\n",
    "        d = d.real\n",
    "        v = v.real\n",
    "        \n",
    "        B = np.matmul(v.T, B)\n",
    "        B = np.matmul(B, v)\n",
    "        \n",
    "        A = np.matmul(v.T, A)\n",
    "        A = np.matmul(A, v)\n",
    "        \n",
    "        U2 = np.zeros((rango, n_eig))\n",
    "        D = np.zeros((n_eig, n_eig))\n",
    "        print('Calculation inverse of B')\n",
    "        inv_B = np.linalg.inv(B)\n",
    "        \n",
    "        for k in tqdm(range(n_eig)):\n",
    "            \n",
    "            d, a = sparse.linalg.eigs(np.matmul(inv_B, A),1, which=option)\n",
    "            d = d.real\n",
    "            a = a.real\n",
    "            \n",
    "            ab = np.matmul(a.T, B)\n",
    "            aba = np.matmul(ab, a)\n",
    "            a = np.divide(a, np.sqrt(aba))\n",
    "            \n",
    "            U2[:,k] = a.flatten()\n",
    "        \n",
    "            D[k,k] = d\n",
    "            \n",
    "            ba = np.matmul(B, a)\n",
    "            aTb = np.matmul(a.T, B)\n",
    "            \n",
    "            dba = d * ba\n",
    "            A = A - np.matmul(dba, aTb)\n",
    "        \n",
    "        U = np.matmul(v, U2)\n",
    "        return U, D, n_eig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib\n",
    "from scipy import linalg, sparse, stats\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def manifold_alignment_wang(data1, data2, mu, lanbda, n_neighbors, n_eigs, n_correspondence, n_cavs):\n",
    "\n",
    "    d1, n1 = data1.shape\n",
    "    d2, n2 = data2.shape\n",
    "\n",
    "    T1 = n1\n",
    "    T2 = n2\n",
    "    \n",
    "    tot_samples = n1 + n2\n",
    "    print(\"Shape of data1:\", data1.shape)\n",
    "    print(\"Shape of data2:\", data2.shape)\n",
    "    \n",
    "    # Transform data to normal distribution\n",
    "    mean_data1 = np.mean(data1.T, axis = 0)\n",
    "    mean_data2 = np.mean(data2.T, axis = 0)\n",
    "    std_data1 = np.std(data1.T, axis = 0)\n",
    "    std_data2 = np.std(data2.T, axis =0)\n",
    "\n",
    "\n",
    "    data1 = np.divide((data1.T - np.matlib.repmat(mean_data1, T1, 1)), \n",
    "                         np.matlib.repmat(std_data1, T1, 1)).T\n",
    "\n",
    "    data2 = np.divide((data2.T - np.matlib.repmat(mean_data2, T2 ,1)),\n",
    "                         np.matlib.repmat(std_data2, T2, 1)).T\n",
    "    \n",
    "    Z = linalg.block_diag(data1, data2) #dimensions (d1+d2, n1+n2)\n",
    "    \n",
    "    # create k-Nearest neighbor graph for data structures \n",
    "    print(\"Computing neighbors dataset 1\")\n",
    "\n",
    "    x1_graph = np.zeros((n1, n1))\n",
    "\n",
    "    #get the nearest neighbors of the data to the CAVS\n",
    "    for n in trange(n1):\n",
    "        x1_cavs_nn = cosine_similarity(data1.T[:n_cavs], data1.T[n].reshape(1,-1))\n",
    "\n",
    "        if n < n_cavs:\n",
    "            x1_cavs_nn_ixs = x1_cavs_nn.argsort(axis=0)[::-1][1:n_neighbors+1].flatten()\n",
    "        else:\n",
    "            x1_cavs_nn_ixs = x1_cavs_nn.argsort(axis=0)[::-1][:n_neighbors+10].flatten()\n",
    "\n",
    "        x1_graph[n,x1_cavs_nn_ixs] = 1\n",
    "\n",
    "    # force CAVs to indicate their nearest image neighbours\n",
    "    for t in trange(n1):\n",
    "        x1_imgs_nn = cosine_similarity(data1.T[n_cavs:], data1.T[t].reshape(1,-1))\n",
    "        if t < n_cavs:\n",
    "            x1_imgs_nn_ixs = x1_imgs_nn.argsort(axis=0)[::-1][:n_neighbors].flatten()\n",
    "\n",
    "        else:\n",
    "            x1_imgs_nn_ixs = x1_imgs_nn.argsort(axis=0)[::-1][1:n_neighbors+1].flatten()\n",
    "\n",
    "        x1_imgs_nn_ixs += n_cavs\n",
    "        x1_graph[t, x1_imgs_nn_ixs] = 1\n",
    "\n",
    "    print('Computing neighbors dataset 2')\n",
    "    x2_graph = np.zeros((n2, n2))\n",
    "    for c in trange(n2):\n",
    "        x2_nn = cosine_similarity(data2.T, data2.T[c].reshape(1,-1))\n",
    "        x2_nn_ixs = x2_nn.argsort(axis=0)[::-1][1:n_neighbors+1].flatten()\n",
    "        x2_graph[c, x2_nn_ixs] = 1\n",
    "        if not np.array_equal(np.where(x2_graph[c] == 1)[0], np.sort(x2_nn_ixs)):\n",
    "            print('The neighbors of dataset 2 do not correspond')\n",
    "    \n",
    "    \n",
    "    # Computing the Laplacians\n",
    "    print('Building Laplacians')\n",
    "    # create topology Laplacian\n",
    "    W = linalg.block_diag(x1_graph, x2_graph)\n",
    "    W = (W + W.T)/2\n",
    "\n",
    "    # create simmilarity matrix\n",
    "    Ws = np.zeros((tot_samples, tot_samples))\n",
    "\n",
    "    Ws1 = np.eye(n1)\n",
    "    Ws2 = np.eye(n2)\n",
    "    Ws3 = np.eye(n_correspondence)\n",
    "\n",
    "    Ws[:n1, :n1] = Ws1\n",
    "    Ws[n1:, n1:] = Ws2\n",
    "    Ws[n1:(n1+n_correspondence), :n_correspondence] = Ws3\n",
    "    Ws[:n_correspondence, n1:(n1+n_correspondence)] = Ws3\n",
    "\n",
    "    Ws = Ws + np.eye(Ws.shape[0])\n",
    "\n",
    "    #create dissimilarity matrix\n",
    "    Wd = np.ones((tot_samples, tot_samples))\n",
    "    np.fill_diagonal(Wd, 0)\n",
    "\n",
    "    Wd1 = np.ones((n_correspondence, n_correspondence))\n",
    "    np.fill_diagonal(Wd1, 0)\n",
    "\n",
    "    Wd[:n_correspondence, n1:(n1+n_correspondence)] = Wd1\n",
    "    Wd[n1:(n1+n_correspondence), :n_correspondence] = Wd1\n",
    "\n",
    "    Wd = Wd + np.eye(Wd.shape[0])\n",
    "\n",
    "    # normalize data\n",
    "    Sws = sum(sum(Ws))\n",
    "    Swd = sum(sum(Wd))\n",
    "    Sw = sum(sum(W))\n",
    "\n",
    "    Ws = Ws / Sws * Sw\n",
    "    Wd = Wd / Swd * Sw\n",
    "\n",
    "    # extract the diagonals\n",
    "    Dd = np.diag(np.sum(Wd, axis=1))\n",
    "    Ds = np.diag(np.sum(Ws, axis = 1))\n",
    "    D = np.diag(np.sum(W, axis=1))\n",
    "\n",
    "    # create laplacians\n",
    "    Ls = Ds - Ws # graph Laplacian of similarity \n",
    "    Ld = Dd - Wd # Laplacian of dissimilarity\n",
    "    L = D - W # Laplacian topology/geometry\n",
    "    \n",
    "    # tune the generalized eigenproblem\n",
    "    A = ((1 - mu) * L + mu * Ls) + lanbda * np.eye((Ls.shape[0]))\n",
    "    B = Ld\n",
    "\n",
    "    ZA = np.matmul(Z, A)\n",
    "    ZB = np.matmul(Z, B)\n",
    "\n",
    "    ZAZ = np.matmul(ZA, Z.T)\n",
    "    ZBZ = np.matmul(ZB, Z.T)\n",
    "    \n",
    "    rank_A = np.linalg.matrix_rank(ZAZ)\n",
    "    rank_B = np.linalg.matrix_rank(ZBZ)\n",
    "    \n",
    "    print(\"Solving generalized eigenvalue decomposition\")\n",
    "    # V = eigenvectors, D = eigenvalues\n",
    "    V, D, n_eig = gen_eig(ZAZ, ZBZ, 'LM', n_eigs, rank_A, rank_B)\n",
    "    \n",
    "    D_idxs = np.diag(D).argsort()\n",
    "    D = np.sort(np.diag(D))\n",
    "    D = D.reshape(D.shape[0],1)\n",
    "    V = V[:, D_idxs]\n",
    "\n",
    "    print(\"Rotating axis if needed\")\n",
    "    #rotate axis if needed\n",
    "    E1 = V[:d1,:]\n",
    "    E2 = V[d1:,:]\n",
    "\n",
    "    sourceXpInv = (-1 * np.matmul(E1.T, data1)).T\n",
    "    sourceXp = np.matmul(E1.T, data1).T\n",
    "    targetXp = np.matmul(E2.T, data2).T\n",
    "\n",
    "    sourceXpInv = stats.zscore(sourceXpInv)\n",
    "    sourceXp = stats.zscore(sourceXp)\n",
    "    targetXp = stats.zscore(targetXp)\n",
    "\n",
    "    ErrRec = np.zeros((n1, V.shape[1]))\n",
    "    ErrRecInv = np.zeros((n1, V.shape[1]))\n",
    "\n",
    "    m1 = np.zeros((n1, V.shape[1]))\n",
    "    m1inv = np.zeros((n1, V.shape[1]))\n",
    "    m2 = np.zeros((n1, V.shape[1]))\n",
    "\n",
    "    for j in trange(V.shape[1]):\n",
    "        for i in range(n1):\n",
    "            m1inv[i,j] = np.mean(sourceXpInv[i, j])\n",
    "            #print('m1inv: ', m1inv)\n",
    "            m1[i,j] = np.mean(sourceXp[i, j])\n",
    "            #print('m1: ', m1)\n",
    "            m2[i,j] = np.mean(targetXp[i, j])\n",
    "            #print('m2: ', m2)\n",
    "\n",
    "            ErrRec[i,j] = np.square(np.power(np.mean(sourceXp[i, j]) - np.mean(targetXp[i, j]), 2))\n",
    "\n",
    "            ErrRecInv[i,j] = np.square(np.power(np.mean(sourceXpInv[i, j]) - np.mean(targetXp[i, j]),2))\n",
    "\n",
    "    Sc = ErrRec.max(axis=0) > ErrRecInv.max(axis=0)\n",
    "    V[:d1, Sc] = V[:d1, Sc] * -1\n",
    "    \n",
    "    Nf = d1+d2\n",
    "    E1 = V[:d1, :Nf]\n",
    "    E2 = V[d1:, :Nf]\n",
    "\n",
    "    X1toF = np.matmul(E1.T, data1)\n",
    "    X2toF = np.matmul(E2.T, data2)\n",
    "\n",
    "    m1 = np.mean(X1toF.T, axis = 0)\n",
    "    m2 = np.mean(X2toF.T, axis = 0)\n",
    "    s1 = np.std(X1toF.T, axis = 0)\n",
    "    s2 = np.std(X2toF.T, axis =0)\n",
    "\n",
    "\n",
    "    XT1toF = np.divide((X1toF.T - np.matlib.repmat(m1, T1, 1)), \n",
    "                         np.matlib.repmat(s1, T1, 1)).T\n",
    "\n",
    "    XT2toF = np.divide((X2toF.T - np.matlib.repmat(m2, T2 ,1)),\n",
    "                         np.matlib.repmat(s2, T2, 1)).T\n",
    "    \n",
    "    return XT1toF, XT1toF, V, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %store -r glove_sorted_t\n",
    "# %store -r cavs_sorted_t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1, x2, eigenvectors, eigenvalues = kernel_manifold_alignment(cavs_sorted_t, glove_sorted_t, mu = 0.9,\n",
    "#                                                               lanbda = 0.5, n_neighbors = 10, n_eigs = 2, \n",
    "#                                                               n_correspondence = 363)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data1: (2048, 1649)\n",
      "Shape of data2: (300, 3009)\n",
      "Computing neighbors dataset 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "063a45a87515457b843d73f36c13cf6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1649), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ecfe823430c4bc983514cfdf14276cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1649), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing neighbors dataset 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fba061039df4c469bf408c96ae0de40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3009), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building Laplacians\n",
      "Solving generalized eigenvalue decomposition\n",
      "Calculating d and v\n",
      "Calculation inverse of B\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23a8254867f14f5b99d64f595b60267c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rotating axis if needed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbca340350b24d08be73e623cc24dbdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# z1, z2, eigenvectors, eigenvalues = manifold_alignment_wang(cavs_sorted_t, glove_sorted_t, mu = 0.9,\n",
    "#                                                             lanbda = 0.5, n_neighbors = 10, n_eigs = 2, \n",
    "#                                                             n_correspondence = 363, n_cavs = 649)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
