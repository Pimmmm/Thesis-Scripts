{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "from p1_TransformToTensor import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SonDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, updated_csv_path, img_path, transform = None):\n",
    "        self.img_path = img_path\n",
    "        self.votes_df = pd.read_csv(updated_csv_path)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        self.img_score = self.votes_df.loc[idx, 'Average']\n",
    "        self.img_name = self.votes_df.loc[idx, 'ID'].astype(str)\n",
    "        self.img_file = []\n",
    "        \n",
    "        for directory, _ , _ in os.walk(self.img_path):\n",
    "            self.img_file.extend(glob.glob(os.path.join(directory, self.img_name + '.jpg')))\n",
    "            \n",
    "        im = Image.open(self.img_file[0])\n",
    "        img_as_img = im.convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            img_as_img = self.transform(img_as_img)\n",
    "            \n",
    "        sample = {'image' : img_as_img,\n",
    "                 'image_score' : self.img_score}\n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(votes_df)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "son_dataset = SonDataset('../data/updated_votes.csv', \n",
    "                         '/raid/data/datasets/SoN/images', \n",
    "                         transform = transforms.Compose([transforms.CenterCrop(224),\n",
    "                                                         transforms.ToTensor(),\n",
    "                                                         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                              std=[0.229, 0.224, 0.225])\n",
    "                                                        ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': tensor([[[-0.1314, -0.2513, -0.5596,  ...,  1.7865,  1.6495,  2.0434],\n",
       "          [-0.0287, -0.1828, -0.3541,  ...,  1.4440,  1.2899,  1.7009],\n",
       "          [-0.0629, -0.2684, -0.2684,  ...,  1.2557,  1.3927,  1.8722],\n",
       "          ...,\n",
       "          [-0.6281, -0.4568, -0.1828,  ..., -0.8849, -0.8335, -0.3027],\n",
       "          [-0.7308, -0.2342,  0.2453,  ..., -0.7822, -0.7137, -0.3541],\n",
       "          [-1.3987, -0.9705, -0.4054,  ..., -0.9192, -0.8507, -0.8507]],\n",
       " \n",
       "         [[-0.0574, -0.1800, -0.4776,  ...,  2.0259,  1.8859,  2.2885],\n",
       "          [ 0.0476, -0.1099, -0.2675,  ...,  1.6758,  1.5182,  1.9384],\n",
       "          [ 0.0126, -0.1975, -0.1800,  ...,  1.4832,  1.6232,  2.1134],\n",
       "          ...,\n",
       "          [-0.7927, -0.6176, -0.3901,  ..., -1.1429, -1.1253, -0.6001],\n",
       "          [-0.8978, -0.3901,  0.1001,  ..., -1.0378, -1.0028, -0.6527],\n",
       "          [-1.5805, -1.1429, -0.5651,  ..., -1.1779, -1.1604, -1.1604]],\n",
       " \n",
       "         [[-0.0964, -0.2184, -0.5147,  ...,  1.6291,  1.4548,  1.8557],\n",
       "          [ 0.0082, -0.1487, -0.3055,  ...,  1.2805,  1.0888,  1.5071],\n",
       "          [-0.0267, -0.2358, -0.2184,  ...,  1.1237,  1.2282,  1.6814],\n",
       "          ...,\n",
       "          [-0.5147, -0.3404, -0.0964,  ..., -0.8284, -0.7238, -0.1487],\n",
       "          [-0.6193, -0.1138,  0.3742,  ..., -0.6890, -0.6018, -0.1835],\n",
       "          [-1.2990, -0.8633, -0.2881,  ..., -0.8284, -0.7064, -0.6890]]]),\n",
       " 'image_score': 40.0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "son_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
