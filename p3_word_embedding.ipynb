{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from KEMA.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.matlib\n",
    "import pickle\n",
    "import random\n",
    "import seaborn as sns\n",
    "import nbimporter\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import linalg, sparse, stats\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from sklearn.preprocessing import normalize, scale\n",
    "from sklearn.neighbors import NearestNeighbors, kneighbors_graph\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn import linear_model\n",
    "from KEMA import gen_eig, kernel_manifold_alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize an English dictionary to filter words from the GloVe dataset. The GloVe dataset used has parsed over Wikipedia and thus contains a lot of noise. This is filtered using a spell check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hunspell\n",
    "spellchecker = hunspell.HunSpell('../data/hunspell/en_US.dic',\n",
    "                                 '../data/hunspell/en_US.aff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_PATH = '/mnt/guanabana/raid/data/datasets/GloVe/pretrained/glove.6B.300d.txt'\n",
    "CAVS_PATH = '../data/filtered_broden_cavs.pickle'\n",
    "EMBEDDING_PATH = '../data/word_embedding_6B_300D.pickle'\n",
    "TEXTURE_PATH = \"/raid/data/datasets/broden1_384/c_texture.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "textures = pd.read_csv(TEXTURE_PATH, index_col = 0)\n",
    "texture_list = list(textures['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the concept activation vectors from the Broden dataset as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CAVS_PATH, 'rb') as handle:\n",
    "        cavs_broden = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the word embeddings from the GloVe dataset. The word embeddings are stored in a dictionary, with the word as key and vector as value, and in a matrix (n_samples x n_features). The original dataset contains about 400K words. All the words are run through a spell checker, if the word is not present in the English dictionary which was used, the word is removed. In total about 280000 words are removed from the GloVe dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(EMBEDDING_PATH):\n",
    "    with open(EMBEDDING_PATH, 'rb') as handle:\n",
    "        embedding_dict = pickle.load(handle)\n",
    "\n",
    "    glove_embedding_matrix = np.load('../data/glove_embedding_matrix.npy')\n",
    "    glove_words = list(embedding_dict.keys())\n",
    "    \n",
    "else:\n",
    "    embedding_dict = {}\n",
    "    glove_words = []\n",
    "    glove_embedding_matrix = np.zeros((400000, 300))\n",
    "\n",
    "    row = 0\n",
    "    # parse through the GloVe data\n",
    "    with open(GLOVE_PATH, 'r', encoding=\"utf-8\") as f:\n",
    "        for line in tqdm(f):\n",
    "            \n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], 'float64').reshape(1,-1)\n",
    "            \n",
    "            # apply a spell check\n",
    "            try:\n",
    "                if spellchecker.spell(word):\n",
    "                    embedding_dict[word] = vector\n",
    "                    glove_embedding_matrix[row] = vector\n",
    "                    glove_words.append(word)\n",
    "                    row +=1\n",
    "            except:\n",
    "                UnicodeEncodeError\n",
    "                    \n",
    "    with open(EMBEDDING_PATH, 'wb') as handle:\n",
    "        pickle.dump(embedding_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    # not all 400K rows are used as a certain amount of words was removed by the spellchecker, \n",
    "    # thus the unused rows are removed from the matrix\n",
    "    glove_embedding_matrix = glove_embedding_matrix[:len(glove_words)]\n",
    "    np.save('../data/glove_embedding_matrix.npy', glove_embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of words left in the GloVe dataset: 118327\n"
     ]
    }
   ],
   "source": [
    "print('The amount of words left in the GloVe dataset:', glove_embedding_matrix.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess CAVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the concepts from the Broden dataset, which are also available as word embedding. Several concepts in the Broden dataset end with _'-s'_. This is removed to get more concepts linked with an embedding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all Broden concepts\n",
    "all_broden_concepts = list(cavs_broden.keys())\n",
    "\n",
    "# remove duplicates from concept list (e.g. mountain-s is stored when mountain and mountain-s are both in the dataset)\n",
    "# and remove the textures from the concepts\n",
    "no_dups_concepts = [c for c in all_broden_concepts if c +'-s' not in all_broden_concepts and c not in texture_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of CAVs left: 649\n"
     ]
    }
   ],
   "source": [
    "print('Amount of CAVs left:', len(no_dups_concepts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a matrix of all cavs\n",
    "cav_matrix = np.zeros((len(no_dups_concepts), cavs_broden[no_dups_concepts[0]]['cav'].shape[1]))\n",
    "for i in range(len(no_dups_concepts)):\n",
    "    cav = cavs_broden[no_dups_concepts[i]]['cav']\n",
    "    cav_matrix[i] = cav\n",
    "\n",
    "# remove the '-s' from the concepts if present \n",
    "broden_concepts = [c[:-2] if c[-2:] == '-s' else c for c in no_dups_concepts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(649, 2048)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cav_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract concepts which have a CAV and a correspondence in the GloVe data. The index is stored to remove the unavailable concepts from the CAV matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the indices and the concepts with a correspondence in both datasets\n",
    "embedding_idxs = [ix for ix, c in enumerate(broden_concepts) if c in embedding_dict.keys()]\n",
    "embedding_concepts = [c for ix, c in enumerate(broden_concepts) if c in embedding_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of CAVs with a corresponding word embedding:  363\n"
     ]
    }
   ],
   "source": [
    "print(\"The amount of CAVs with a corresponding word embedding: \", len(embedding_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the selected CAVs\n",
    "cavs_with_embedding = cav_matrix[embedding_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(363, 2048)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cavs_with_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check if the subsetting was done correctly, the cav_matrix is compared with the original cavs\n",
    "# When correct, this should NOT print anything\n",
    "for ik, kk in enumerate(embedding_idxs):\n",
    "    if not np.array_equal(cavs_broden[no_dups_concepts[kk]]['cav'], cavs_with_embedding[ik].reshape(1,-1)):\n",
    "        print(kk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create matrix with CAVs which do not have a matching word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cav_no_glove = np.delete(cav_matrix, embedding_idxs, axis=0)\n",
    "cav_no_glove_concepts = [conc for conc in broden_concepts if conc not in embedding_concepts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching vectors\n"
     ]
    }
   ],
   "source": [
    "# To check if the subsetting was done correctly, the cav_matrix is compared with the original cavs\n",
    "# When correct, this should print \"matching vectors\"\n",
    "no_match = []\n",
    "for iz, zz in enumerate(cav_no_glove_concepts):\n",
    "    try:\n",
    "        if not np.array_equal(cavs_broden[zz+'-s']['cav'], cav_no_glove[iz].reshape(1,-1)):\n",
    "            no_match.append([iz,zz])\n",
    "            print(iz, zz)\n",
    "    except:\n",
    "        KeyError\n",
    "        if not np.array_equal(cavs_broden[zz]['cav'], cav_no_glove[iz].reshape(1,-1)):\n",
    "            no_match.append([iz,zz])\n",
    "            print(iz, zz)\n",
    "\n",
    "if len(no_match) == 0:\n",
    "        print('Matching vectors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the CAV matrices to norm-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cavs_norm = normalize(cavs_with_embedding,axis=1)\n",
    "cav_no_glove_norm = normalize(cav_no_glove, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the matrices back together, the first 363 samples have a correspondence in the GloVe dataset, while the other part is used to better capture the structure of the CAV manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cavs_sorted = np.concatenate((cavs_norm, cav_no_glove_norm))\n",
    "cavs_sorted_concept = embedding_concepts + cav_no_glove_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(cavs_sorted.shape[0] == len(cavs_sorted_concept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include SoN image in the Manifold Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read SoN info, where the ID equals the image name in the folder structure\n",
    "son_info = pd.read_csv('../data/son_votes.csv', index_col = 0)\n",
    "\n",
    "with open('../data/son_tensors.pickle', 'rb') as handle:\n",
    "        son_tensors = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From each score range (0-1, 1-2, ..., 9-10) 100 images are randomly sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "son_manifold_imgs = []\n",
    "for i in range(10):\n",
    "    son_subset_idxs = list(son_info.query('Average > %s & Average <= %s' % (str(i), str(i+1))).index)\n",
    "    son_random_idxs = random.sample(son_subset_idxs, 100)\n",
    "    son_manifold_imgs.extend(son_random_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(son_manifold_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a matrix of the tensors of the random selected images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "son_manifold_matrix = np.zeros((len(son_manifold_imgs), 2048))\n",
    "for a, ix in enumerate(son_manifold_imgs):\n",
    "    img_name_in_df = str(son_info.loc[ix, 'ID'])\n",
    "    if ix >= 52642:\n",
    "        ix += 1\n",
    "    if ix >= 201047:\n",
    "        ix += 1\n",
    "    img_name_in_dict = son_tensors[str(ix)][0]\n",
    "    \n",
    "    if img_name_in_df != img_name_in_dict:\n",
    "        print(a)\n",
    "        \n",
    "    else:\n",
    "        img_tensor = son_tensors[str(ix)][2].numpy()\n",
    "        son_manifold_matrix[a] = img_tensor\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the data to unit length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "son_manifold_matrix = normalize(son_manifold_matrix, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the neighbors for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df89ad309fbe424fbf5aa3d372553b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "son_imgs_neighbors_dict = {}\n",
    "\n",
    "for jj in trange(len(son_manifold_imgs)):\n",
    "    img_nn = cosine_similarity(son_manifold_matrix, son_manifold_matrix[jj].reshape(1,-1)).flatten()\n",
    "    img_nn_ixs = img_nn.argsort()[::-1][1:11]\n",
    "    son_imgs_neighbors_dict[str(jj)] = img_nn_ixs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add SoN to CAVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cavs_sorted_son = np.concatenate((cavs_sorted, son_manifold_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1649, 2048)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cavs_sorted_son.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a matrix of the word embeddings for the concepts which also have a CAV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_with_cav = np.zeros((len(embedding_idxs), 300))\n",
    "for i in range(len(embedding_concepts)):\n",
    "    word_vec = embedding_dict[embedding_concepts[i]].reshape(1,-1)\n",
    "    embeddings_with_cav[i] = word_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(363, 300)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_with_cav.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create matrix with GloVe embeddings which do not have a matching CAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate a matrix with the required shape\n",
    "glove_no_cav = np.zeros((len(glove_words) - len(embedding_concepts), 300))\n",
    "\n",
    "# Also store the GloVe concept names (which do not have a match in CAV)\n",
    "glove_no_cav_concept = []\n",
    "\n",
    "idx = 0\n",
    "for concpt in embedding_dict.keys():\n",
    "    if concpt not in embedding_concepts:\n",
    "        glove_no_cav_concept.append(concpt)\n",
    "        concpt_vec = embedding_dict[concpt]\n",
    "        glove_no_cav[idx] = concpt_vec\n",
    "        idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117964, 300)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_no_cav.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize all data to norm-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_norm = normalize(embeddings_with_cav,axis=1)\n",
    "glove_no_cav_norm = normalize(glove_no_cav, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the nearest neighbors of the GloVe embeddings which do have correspondence with CAVs. These are used in the manifold alignment to preserve the structure of the GloVe data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of unique indices of the nearest neigbors to the GloVe embeddings which have a correspondence with a CAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d5f9164e46402f8f095a05d7dabb73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=363), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# takes about 3min to run\n",
    "glove_neighbors = []\n",
    "for k in trange(embeddings_with_cav.shape[0]):\n",
    "    glove_cosim = cosine_similarity(glove_no_cav_norm, glove_norm[k].reshape(1,-1))\n",
    "    glove_cosim_ixs = glove_cosim.argsort(axis=0)[::-1][:10]\n",
    "#     print(embedding_concepts[k])\n",
    "#     print('--------')\n",
    "    for ixs in glove_cosim_ixs:\n",
    "#         print(glove_no_cav_concept[ixs.item()])\n",
    "        if ixs.item() not in glove_neighbors:\n",
    "            glove_neighbors.append(ixs.item())\n",
    "#     print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique neighours found: 2646\n"
     ]
    }
   ],
   "source": [
    "print('The number of unique neighours found:', len(glove_neighbors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the nearest neighbours from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_no_cav_nneigh = glove_no_cav_norm[glove_neighbors]\n",
    "glove_no_cav_concept_nneigh = [glove_no_cav_concept[neigh] for neigh in glove_neighbors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the matrices correspond\n",
    "# if the data matches nothing should be printed\n",
    "for q in range(len(glove_neighbors)):\n",
    "    if not np.array_equal(embedding_dict[glove_no_cav_concept_nneigh[q]], glove_no_cav[glove_neighbors[q]].reshape(1,-1)):\n",
    "        print('The data do not correspond for concept:', glove_no_cav_concept_nneigh[q])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the GloVe data together, the first 363 rows have correspondence in the CAV dataset. The other data is used the preserve the structure of the GloVe manifold during the alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_sorted = np.concatenate((glove_norm, glove_no_cav_nneigh))\n",
    "glove_sorted_concept = embedding_concepts.copy()\n",
    "glove_sorted_concept.extend(glove_no_cav_concept_nneigh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the sorted datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embedding_matrix_norm = normalize(glove_embedding_matrix)\n",
    "\n",
    "for ip, p in enumerate(glove_sorted_concept):\n",
    "    cix = glove_words.index(p)\n",
    "    origin_vec= glove_embedding_matrix_norm[cix].reshape(1,-1)\n",
    "    if not np.array_equal(origin_vec, glove_sorted[ip].reshape(1,-1)):\n",
    "        print(p) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cavs_sorted_t = cavs_sorted_son.T\n",
    "glove_sorted_t = glove_sorted.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store cavs_sorted_t\n",
    "%store glove_sorted_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Amount of CAVs used:', cavs_sorted_son.shape[0])\n",
    "print('Amount of GloVes used:', glove_sorted.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manifold alignment using Linear Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to solve the generalized eigenvalue decomposition, which is a copy of the MatLab implementation of Devis Tuia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform manifold allignment the MatLab code from Devis Tuia is followed: https://github.com/dtuia/KEMA/blob/master/general_routine/KMA.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2, eigenvectors, eigenvalues = kernel_manifold_alignment(cavs_sorted_t, glove_sorted_t, mu = 0.9,\n",
    "                                                              lanbda = 0.5, n_neighbors = 10, n_eigs = 2, \n",
    "                                                              n_correspondence = 363)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manifold Alignment Wang '11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50)\n",
    "X1_trans = pca.fit_transform(cavs_sorted_t.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1649, 50)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1, z2, eigenvectors, eigenvalues = manifold_alignment_wang(cavs_sorted_t, glove_sorted_t, mu = 0.9,\n",
    "                                                            lanbda = 0.5, n_neighbors = 10, \n",
    "                                                            n_eigs = 50, \n",
    "                                                            n_correspondence = 363, n_cavs = 649)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of different alignment is stored:\n",
    "- dimensions keep track of the different dimensions used\n",
    "- accuracy: is the accuracy of nearest neighbor alignment\n",
    "- variables: \n",
    "    - T1: mu = 0.5\n",
    "    - T2: mu = 0.6\n",
    "    - T3: mu = 0.7\n",
    "    - T4: mu = 0.8\n",
    "    - T5: mu = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('../data/manifold_alignment_accuracy.pickle'):\n",
    "    with open('../data/manifold_alignment_accuracy.pickle', 'rb') as handle:\n",
    "        manifold_alignment_accuracy = pickle.load(handle)\n",
    "        \n",
    "else:\n",
    "    manifold_alignment_accuracy = {'dimensions':[],\n",
    "                                  'CAV_accuracy': [],\n",
    "                                  'variables': [],\n",
    "                                  'GloVe_accuracy':[]}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 649)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "son_imgs_neighbors_matrix = x1_graph[len(cavs_sorted_concept):, :len(cavs_sorted_concept)]\n",
    "son_imgs_neighbors_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print neighbors in the glove dataset\n",
    "# glove_neighbors_dict = {}\n",
    "# for ix, c in enumerate(glove_sorted_concept):\n",
    "# #     glove_cos_neighbors = np.where(x2_graph[ix] ==1)[0]\n",
    "#     glove_neighbors_dict[c] = []\n",
    "\n",
    "#     print(c)\n",
    "#     print('---------')\n",
    "#     for n in np.nditer(glove_cos_neighbors):\n",
    "#         print(glove_sorted_concept[n.item()])\n",
    "#         glove_neighbors_dict[c].append(glove_sorted_concept[n.item()])\n",
    "#     print('\\n')\n",
    "# #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAV domain to CAV common space comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cav_cav_nn = x1_graph[:len(cavs_sorted_concept), :len(cavs_sorted_concept)]\n",
    "\n",
    "cav_cav_common_accuracy = 0\n",
    "cav_cav_total_neighbours = 0\n",
    "\n",
    "for c, v in tqdm(enumerate(cavs_sorted_concept)):\n",
    "    correct_cav_nn = 0\n",
    "    cossim_cav = cosine_similarity(XT1toF.T[:len(cavs_sorted_concept)], XT1toF.T[c].reshape(-1,n_eigs))\n",
    "    cossim_cav_idxs = cossim_cav.argsort(axis=0)[::-1][1:11].flatten()\n",
    "    cav_cav_total_neighbours += len(cossim_cav_idxs)\n",
    "    \n",
    "    cav_nn_cavdomain = np.where(cav_cav_nn[c] == 1)[0].flatten()\n",
    "    for z in np.nditer(cossim_cav_idxs):\n",
    "        if z.item() in cav_nn_cavdomain:\n",
    "            correct_cav_nn +=1 \n",
    "            \n",
    "    cav_cav_common_accuracy += correct_cav_nn\n",
    "cav_cav_common_accuracy = cav_cav_common_accuracy / cav_cav_total_neighbours * 100\n",
    "\n",
    "print('CAV to CAV accuracy:', round(cav_cav_common_accuracy, 3),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate a accuracy metric of the manifold alignment. The nearest neighbors of the transformed CAVs are calculated and compared with the nearest neighbors of this concept in the GloVe domain. The comparison is based on exact matches and not on semantic similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_nn_accuracy = 0\n",
    "total_neighbours_cav = 0\n",
    "\n",
    "for p, w in tqdm(enumerate(embedding_concepts)):\n",
    "    correct_nn = 0\n",
    "    \n",
    "    cos_sim = cosine_similarity(XT2toF.T, XT1toF.T[p].reshape(-1,n_eigs))\n",
    "    top_10_nn = cos_sim.argsort(axis=0)[::-1][1:11]\n",
    "    total_neighbours_cav += len(top_10_nn)\n",
    "    \n",
    "    glove_domain_nn = glove_neighbors_dict[w]\n",
    "    for e in top_10_nn:\n",
    "        if glove_sorted_concept[e.item()] in glove_domain_nn:\n",
    "            correct_nn += 1\n",
    "    average_nn_accuracy += correct_nn\n",
    "    \n",
    "average_nn_accuracy /= total_neighbours_cav\n",
    "# manifold_alignment_accuracy['CAV_accuracy'].append(average_nn_accuracy)\n",
    "\n",
    "print(\"CAV to GloVe accuracy: \", round(average_nn_accuracy,3) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the GloVe neighbors in the common feature space to the GloVe neighbors in the GloVe domain. The accuracy is based on exact matches and not on semantic similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_glove_accuracy = 0\n",
    "total_neighbours_glove = 0\n",
    "\n",
    "for p, w in tqdm(enumerate(embedding_concepts)):\n",
    "    correct_nn = 0\n",
    "    cos_sim = cosine_similarity(XT2toF.T, XT2toF.T[p].reshape(-1,n_eigs))\n",
    "    top_10_nn = cos_sim.argsort(axis=0)[::-1][1:11]\n",
    "    total_neighbours_glove += len(top_10_nn)\n",
    "    \n",
    "    glove_domain_nn = glove_neighbors_dict[w]\n",
    "    for e in top_10_nn:\n",
    "        if glove_sorted_concept[e.item()] in glove_domain_nn:\n",
    "            correct_nn += 1\n",
    "    \n",
    "    glove_glove_accuracy += correct_nn\n",
    "    \n",
    "glove_glove_accuracy /= total_neighbours_glove\n",
    "# manifold_alignment_accuracy['GloVe_accuracy'].append(glove_glove_accuracy)\n",
    "\n",
    "print(\"GloVe to GloVe accuracy: \", round(glove_glove_accuracy,3) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manifold_alignment_accuracy['dimensions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "fig = sns.lineplot(x='dimensions', y='CAV_accuracy', hue='variables', data=manifold_alignment_accuracy)\n",
    "plt.title('CAV to GloVe accuracy in common feature space')\n",
    "fig.set(xlabel='Number of dimensions', ylabel='Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "ax = sns.lineplot(x='dimensions', y='GloVe_accuracy', hue = 'variables', data=manifold_alignment_accuracy)\n",
    "plt.title('Glove to Glove accuracy in the common feature space')\n",
    "fig.set(xlabel = 'Number of dimensions', ylabel= 'Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/manifold_alignment_accuracy.pickle', 'wb') as handle:\n",
    "        pickle.dump(manifold_alignment_accuracy, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print CAV neighbors in the common feature space\n",
    "counter = 0\n",
    "print(\"Dim:\", n_eigs)\n",
    "print('MU:', MUW)\n",
    "print('LANBDA:', LAMBDAW,'\\n')\n",
    "for i in range(n_samples):\n",
    "    cosim = cosine_similarity(XT2toF.T, XT1toF.T[i].reshape(-1,n_eigs))\n",
    "    ixs = cosim.argsort(axis=0)[::-1][0:10]\n",
    "    print('Transformed CAV concept:',embedding_concepts[i])\n",
    "    print('Closest aligned transformed GloVe concepts:')\n",
    "    print('-------')\n",
    "    for j in ixs:\n",
    "        try:\n",
    "            print(glove_sorted_concept[j.item()])\n",
    "        except:\n",
    "            IndexError\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "print(\"Dim:\", n_eigs)\n",
    "print('MU:', MUW)\n",
    "print('LANBDA:', LAMBDAW,'\\n')\n",
    "for i in range(n_samples):\n",
    "    cosim = cosine_similarity(XT2toF.T, XT2toF.T[i].reshape(-1,n_eigs))\n",
    "    ixs = cosim.argsort(axis=0)[::-1][0:10]\n",
    "    print('Transformed GloVe concept:',embedding_concepts[i])\n",
    "    print('Closest aligned transformed GloVe concepts:')\n",
    "    print('-------')\n",
    "    for j in ixs:\n",
    "        try:\n",
    "            print(glove_sorted_concept[j.item()])\n",
    "        except:\n",
    "            IndexError\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_accuracy = 0\n",
    "cav_accuracy = 0\n",
    "\n",
    "for i in range(len(son_manifold_imgs)):\n",
    "    correct_img = 0\n",
    "    correct_cav = 0\n",
    "    \n",
    "    imgs_neigh = np.where(x1_graph[len(cavs_sorted_concept) + i, len(cavs_sorted_concept):])[0]\n",
    "    cavs_neigh = np.where(x1_graph[len(cavs_sorted_concept):, :len(cavs_sorted_concept)])[0]\n",
    "    \n",
    "    \n",
    "    cos_imgs = cosine_similarity(XT1toF.T[len(cavs_sorted_concept):], XT1toF.T[len(cavs_sorted_concept):][i].reshape(-1,n_eigs))\n",
    "    cos_cavs = cosine_similarity(XT1toF.T[:len(cavs_sorted_concept)], XT1toF.T[len(cavs_sorted_concept):][i].reshape(-1, n_eigs))\n",
    "    \n",
    "    imgs_nn_ixs = cos_imgs.argsort(axis=0)[::-1][1:11]\n",
    "    cavs_nn_ixs = cos_cavs.argsort(axis=0)[::-1][:10].flatten()\n",
    "    \n",
    "#     ##### Print concepts\n",
    "#     print('Image', str(i))\n",
    "#     print('Nearest CAVs in CAV domain:')\n",
    "#     print('---------')\n",
    "#     for t in np.nditer(cavs_neigh):\n",
    "#         print(cavs_sorted_concept[t.item()])\n",
    "        \n",
    "#     print('\\n')\n",
    "#     print('Nearest CAVs in common domain:')\n",
    "#     print(' --------')\n",
    "#     print('\\n')\n",
    "    \n",
    "#     for q in np.nditer(cavs_nn_ixs):\n",
    "#         print(cavs_sorted_concept[q.item()])\n",
    "#     #############\n",
    "    \n",
    "    \n",
    "    for j in np.nditer(imgs_nn_ixs):\n",
    "        if j.item() in imgs_neigh:\n",
    "            correct_img += 1\n",
    "     \n",
    "    img_accuracy += correct_img\n",
    "    \n",
    "    for q in np.nditer(cavs_nn_ixs):\n",
    "        if q.item() in cavs_neigh:\n",
    "            correct_cav +=1\n",
    "    break\n",
    "    \n",
    "img_accuracy = img_accuracy/(len(son_manifold_imgs) * 10)\n",
    "cav_accuracy = cav_accuracy/(len(son_manifold_imgs) * 10)\n",
    "print('Accuracy of neighbouring images:', img_accuracy*100)\n",
    "print('Accuracy of neighbouring CAVs:', cav_accuracy*100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(imgs_neigh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore new concepts related to scenicness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the 1000 most scenic images in the ScenicOrNot dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the dataframe in descending order\n",
    "sorted_son_info = son_info.sort_values(by='Average', ascending=False)\n",
    "\n",
    "# extract the indices of the first 1000 images and the last 1000\n",
    "most_scenic_ixs = np.asarray(sorted_son_info.iloc[:1000,:].index)\n",
    "least_scenic_ixs = np.asarray(sorted_son_info.iloc[-1000:,:].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_scenic_matrix = np.zeros((len(most_scenic_ixs), 2048))\n",
    "for a, ix in enumerate(most_scenic_ixs):\n",
    "    img_name_in_df = str(son_info.loc[ix, 'ID'])\n",
    "    if ix >= 52642:\n",
    "        ix += 1\n",
    "    if ix >= 201047:\n",
    "        ix += 1\n",
    "    img_name_in_dict = son_tensors[str(ix)][0]\n",
    "    \n",
    "    if img_name_in_df != img_name_in_dict:\n",
    "        print(a)\n",
    "        \n",
    "    else:\n",
    "        img_tensor = son_tensors[str(ix)][2].numpy()\n",
    "        most_scenic_matrix[a] = img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_scenic_matrix = np.zeros((len(least_scenic_ixs), 2048))\n",
    "for a, ix in enumerate(least_scenic_ixs):\n",
    "    img_name_in_df = str(son_info.loc[ix, 'ID'])\n",
    "    if ix >= 52642:\n",
    "        ix += 1\n",
    "    if ix >= 201047:\n",
    "        ix += 1\n",
    "    img_name_in_dict = son_tensors[str(ix)][0]\n",
    "    \n",
    "    if img_name_in_df != img_name_in_dict:\n",
    "        print(a)\n",
    "        \n",
    "    else:\n",
    "        img_tensor = son_tensors[str(ix)][2].numpy()\n",
    "        least_scenic_matrix[a] = img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_scenic_matrix = normalize(most_scenic_matrix)\n",
    "least_scenic_matrix = normalize(least_scenic_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for CAV concepts in the CAV domain for most scenic images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenic_cav_concepts = []\n",
    "for im in trange(most_scenic_matrix.shape[0]):\n",
    "    cos_sim_cav_idxs = cosine_similarity(cavs_sorted, most_scenic_matrix[im].reshape(1,-1)).flatten()\n",
    "    top10_cav = cos_sim_cav_idxs.argsort()[::-1][:10] # select the closest 20 neighbours to every image\n",
    "    # add the concept to the list\n",
    "    for ix in np.nditer(top10_cav):\n",
    "        scenic_cav_concepts.append(cavs_sorted_concept[ix.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_scenic_cav_concepts = list(set(scenic_cav_concepts))\n",
    "cav_concepts_dict = {'Concepts' : cavs_sorted_concept,\n",
    "                    'Frequency': [scenic_cav_concepts.count(x) for x in cavs_sorted_concept]\n",
    "                    }\n",
    "\n",
    "cav_concepts_df = pd.DataFrame.from_dict(cav_concepts_dict)\n",
    "cav_concepts_df.sort_values(by='Frequency', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cav_concepts_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the images to the common space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_scenic_matrix_t = most_scenic_matrix.T\n",
    "least_scenic_matrix_t = least_scenic_matrix.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the images to the common feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenic_imgs_transform = np.matmul(E1.T, most_scenic_matrix_t)\n",
    "unscenic_imgs_transform = np.matmul(E1.T, least_scenic_matrix_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data to normal distribution using the mean and std of the training data\n",
    "\n",
    "T3 = most_scenic_matrix_t.shape[1]\n",
    "T4 = least_scenic_matrix_t.shape[1]\n",
    "\n",
    "m3 = np.mean(scenic_imgs_transform.T, axis = 0)\n",
    "m4 = np.mean(unscenic_imgs_transform.T, axis = 0)\n",
    "s3 = np.std(scenic_imgs_transform.T, axis = 0)\n",
    "s4 = np.std(unscenic_imgs_transform.T, axis =0)\n",
    "\n",
    "scenic_imgs = np.divide((scenic_imgs_transform.T - np.matlib.repmat(m1, T3, 1)), \n",
    "                     np.matlib.repmat(s1, T3, 1)).T\n",
    "\n",
    "unscenic_imgs = np.divide((unscenic_imgs_transform.T - np.matlib.repmat(m1, T4, 1)), \n",
    "                     np.matlib.repmat(s1, T4, 1)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for CAV concepts in the common space for the most scenic images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cav_concept_commonspace = []\n",
    "for i in trange(scenic_imgs.shape[1]):\n",
    "    sc_idxs = cosine_similarity(XT1toF.T[:649], scenic_imgs.T[i].reshape(1,-1)).flatten()\n",
    "    sc_idxs = sc_idxs.argsort()[::-1][:10]\n",
    "    for ix in np.nditer(sc_idxs):\n",
    "        cav_commonspace_concept = cavs_sorted_concept[ix.item()]\n",
    "        new_cav_concept_commonspace.append(cav_commonspace_concept)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_new_cav_concepts = list(set(new_cav_concept_commonspace))\n",
    "cav_commonspace_dict = {'Concept': cavs_sorted_concept,\n",
    "                       'Frequency': [new_cav_concept_commonspace.count(o) for o in cavs_sorted_concept]}\n",
    "\n",
    "cav_commonspace_df = pd.DataFrame.from_dict(cav_commonspace_dict)\n",
    "cav_commonspace_df.sort_values(by='Frequency', inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cav_commonspace_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for new concepts in the Glove data in the common space for the most scenic images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_glove_concept_commonspace = []\n",
    "for i in trange(len(most_scenic_ixs)):\n",
    "    sc_idxs = cosine_similarity(XT2toF.T, scenic_imgs.T[i].reshape(1,-1))\n",
    "    sc_idxs = sc_idxs.argsort(axis=0)[::-1][:10]\n",
    "    for ix in np.nditer(sc_idxs):\n",
    "        glove_commonspace_concept = glove_sorted_concept[ix.item()]\n",
    "        new_glove_concept_commonspace.append(glove_commonspace_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_commonspace_dict = {'Concept': glove_sorted_concept,\n",
    "                       'Frequency': [new_glove_concept_commonspace.count(u) for u in glove_sorted_concept]}\n",
    "\n",
    "glove_commonspace_df = pd.DataFrame.from_dict(glove_commonspace_dict)\n",
    "glove_commonspace_df.sort_values(by='Frequency', inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_commonspace_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the similar CAVs to the least scenic images in the CAV domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unscenic_cav_concepts = []\n",
    "for im in trange(least_scenic_matrix.shape[0]):\n",
    "    cos_unsim_cav_idxs = cosine_similarity(cavs_sorted, least_scenic_matrix[im].reshape(1,-1))\n",
    "    top10_cav = cos_unsim_cav_idxs.argsort(axis=0)[::-1][:10] # select the closest 20 neighbours to every image\n",
    "    # add the concept to the list\n",
    "    for ix in np.nditer(top10_cav):\n",
    "        unscenic_cav_concepts.append(cavs_sorted_concept[ix.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_unscenic_cav_concepts = list(set(unscenic_cav_concepts))\n",
    "uncav_concepts_dict = {'Concepts' : cavs_sorted_concept,\n",
    "                    'Frequency': [unscenic_cav_concepts.count(x) for x in cavs_sorted_concept]\n",
    "                    }\n",
    "\n",
    "uncav_concepts_df = pd.DataFrame.from_dict(uncav_concepts_dict)\n",
    "uncav_concepts_df.sort_values(by='Frequency', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncav_concepts_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for CAV concepts in the common domain for the least scenic images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unscenic_cavs_concept_common = []\n",
    "for i in trange(unscenic_imgs.shape[1]):\n",
    "    unsc_idxs = cosine_similarity(XT1toF.T[:649], unscenic_imgs.T[i].reshape(1,-1)).flatten()\n",
    "    unsc_idxs = unsc_idxs.argsort()[::-1][:10]\n",
    "    for ix in np.nditer(unsc_idxs):\n",
    "        unscenic_cavs_concept_common.append(cavs_sorted_concept[ix.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unscenic_cavs_common_dict = {'Concepts' : cavs_sorted_concept,\n",
    "                            'Frequency' : [unscenic_cavs_concept_common.count(c) for c in cavs_sorted_concept]}\n",
    "\n",
    "unscenic_cavs_common_df = pd.DataFrame.from_dict(unscenic_cavs_common_dict)\n",
    "unscenic_cavs_common_df.sort_values(by='Frequency', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unscenic_cavs_common_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for GloVe concepts in the common domain for the least scenic images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_glove_unscenic_concept_commonspace = []\n",
    "for i in trange(len(least_scenic_ixs)):\n",
    "    unsc_idxs = cosine_similarity(XT2toF.T, unscenic_imgs.T[i].reshape(1,-1))\n",
    "    unsc_idxs = unsc_idxs.argsort(axis=0)[::-1][:10]\n",
    "    for ix in np.nditer(unsc_idxs):\n",
    "        glove_commonspace_unscenic_concept = glove_sorted_concept[ix.item()]\n",
    "        new_glove_unscenic_concept_commonspace.append(glove_commonspace_unscenic_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_unscenic_glove_concepts = list(set(new_glove_unscenic_concept_commonspace))\n",
    "unglove_commonspace_dict = {'Concept': unique_unscenic_glove_concepts,\n",
    "                       'Frequency': [new_glove_unscenic_concept_commonspace.count(u) for u in unique_unscenic_glove_concepts]}\n",
    "\n",
    "unglove_commonspace_df = pd.DataFrame.from_dict(unglove_commonspace_dict)\n",
    "unglove_commonspace_df.sort_values(by='Frequency', inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unglove_commonspace_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert images to CAVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get most scenic image tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_ix = sorted_son_info.iloc[0,].name\n",
    "img_id = sorted_son_info.loc[test_img_ix, 'ID']\n",
    "\n",
    "if test_img_ix >= 52642:\n",
    "    test_img_ix += 1\n",
    "if test_img_ix >= 201047:\n",
    "    test_img_ix += 1\n",
    "        \n",
    "test_img_tensor = son_tensors[str(test_img_ix)][2].numpy().reshape(1,-1)\n",
    "\n",
    "y1 = np.asarray([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_son_info.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample counter images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_imgs_idxs = []\n",
    "for i in range(1,8):\n",
    "    imgs_idxs = list(sorted_son_info.query('Average > %s & Average <= %s' % (str(i), str(i+1))).index)\n",
    "    sample_imgs_idxs = random.sample(imgs_idxs, 100)\n",
    "    for ix in sample_imgs_idxs:\n",
    "        if ix >= 52642:\n",
    "            ix +=1 \n",
    "        if ix >= 201047:\n",
    "            ix += 1\n",
    "        counter_imgs_idxs.append(ix)\n",
    "y2 = np.zeros(len(counter_imgs_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_imgs_matrix = np.zeros((len(counter_imgs_idxs), test_img_tensor.shape[1]))\n",
    "for j, ix in enumerate(counter_imgs_idxs):\n",
    "    counter_imgs_matrix[j] = son_tensors[str(ix)][2].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((test_img_tensor, counter_imgs_matrix))\n",
    "y = np.concatenate((y1, y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = linear_model.SGDClassifier()\n",
    "lm.fit(X, y)\n",
    "lm_cav = lm.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform image CAV to common feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cav = normalize(lm_cav)\n",
    "img_cav_t = img_cav.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_cav.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cav_transform = np.matmul(E1.T, img_cav_t)\n",
    "\n",
    "T5 = cav_transform.shape[1]\n",
    "\n",
    "cav_transform = np.divide((cav_transform.T - np.matlib.repmat(m1, T5, 1)), \n",
    "                     np.matlib.repmat(s1, T5, 1)).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for aligned transformed CAVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_cavs = []\n",
    "cavs_idxs = cosine_similarity(XT1toF.T[:649], cav_transform.T.reshape(1,-1)).flatten()\n",
    "cavs_idxs = cavs_idxs.argsort()[::-1][:10]\n",
    "for ix in np.nditer(cavs_idxs):\n",
    "    aligned_cavs.append(cavs_sorted_concept[ix.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_cavs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "def getPath(img_name):\n",
    "    img_file = []\n",
    "    for directory, _ , _ in os.walk('/raid/data/datasets/SoN/images'):\n",
    "        img_file.extend(glob.glob(os.path.join(directory, img_name + '.jpg')))\n",
    "\n",
    "    return img_file[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = sorted_son_info.loc[test_img_ix, 'ID']\n",
    "test_img_path = getPath(str(img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = plt.imread(test_img_path)\n",
    "plt.imshow(im)\n",
    "plt.grid(b=None)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
