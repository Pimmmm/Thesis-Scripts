{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from random import randint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/raid/home/arend036/msc_pim/Thesis-Scripts'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_EMBEDDING_PATH = '/mnt/guanabana/raid/data/datasets/GloVe/pretrained' \n",
    "GLOVE_PATH = WORD_EMBEDDING_PATH + '/glove.42B.300d.txt'\n",
    "CAVS_PATH = '../data/filtered_broden_cavs.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CAVS_PATH, 'rb') as handle:\n",
    "        cavs_broden = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1007322edae749938aad44c1450a981a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# takes about 4 - 8min to run on guanabana\n",
    "\n",
    "embedding_dict = {} # 1.9M words\n",
    "\n",
    "with open(GLOVE_PATH, 'r', encoding=\"utf-8\") as f:\n",
    "    for line in tqdm(f):\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], 'float32')\n",
    "        embedding_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = list(cavs_broden.keys())\n",
    "embedding_concepts = [c for c in concepts if c in embedding_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all the concepts which have a concept activation vector and have a word embedding, the CAVs are concatenated into a matrix. Also the matching word embeddings are concatenated into a matrix. <br>\n",
    "These are then split in 75% training and 25% test data and converted into a TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cavs = torch.from_numpy(cavs_broden[embedding_concepts[0]]['cav']).float()\n",
    "y_word_vec = torch.from_numpy(embedding_dict[embedding_concepts[0]]).unsqueeze(0).float()\n",
    "\n",
    "for i in range(1, len(embedding_concepts)):\n",
    "    cav = torch.from_numpy(cavs_broden[embedding_concepts[i]]['cav']).float()\n",
    "    x_cavs = torch.cat((x_cavs, cav), 0)\n",
    "    \n",
    "    word_vec = torch.from_numpy(embedding_dict[embedding_concepts[i]]).unsqueeze(0).float()\n",
    "    y_word_vec = torch.cat((y_word_vec, word_vec), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly sample 25% indices of the matrices \n",
    "random.seed(42)\n",
    "random_idxs = random.sample(range(len(embedding_concepts)), 80)\n",
    "random_idxs.sort()\n",
    "\n",
    "X_train = np.delete(x_cavs, random_idxs, axis=0)\n",
    "X_test = x_cavs[random_idxs,:]\n",
    "\n",
    "y_train = np.delete(y_word_vec, random_idxs, axis=0)\n",
    "y_test = y_word_vec[random_idxs,:]\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 10)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_concepts = [embedding_concepts[i] for i in random_idxs] # store the words/concepts which will be used for testing\n",
    "x_concepts = [word for word in embedding_concepts if word not in y_concepts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a simple neural network which is a linear function between the concept activation vectors and the word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(2048, 300)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "net = Net()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the optimizer and the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7710, grad_fn=<MseLossBackward>)\n",
      "tensor(0.7898, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3878, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2123, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1327, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = '../models/cav_to_word_net.pth'\n",
    "\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    net = Net()\n",
    "    net.load_state_dict(torch.load(MODEL_PATH))\n",
    "    \n",
    "else:\n",
    "    \n",
    "    for epoch in range(5):\n",
    "\n",
    "        for data in train_loader:\n",
    "            X, y = data\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(X)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(loss)\n",
    "        torch.save(net.state_dict(), MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = list(net.parameters())[0]\n",
    "bias = net.fc1.bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person',\n",
       " 'metal',\n",
       " 'plant',\n",
       " 'neck',\n",
       " 'carpet',\n",
       " 'ground',\n",
       " 'mountain',\n",
       " 'muzzle',\n",
       " 'railing',\n",
       " 'book',\n",
       " 'flower',\n",
       " 'paw',\n",
       " 'dog',\n",
       " 'body',\n",
       " 'headboard',\n",
       " 'cat',\n",
       " 'plate',\n",
       " 'bicycle',\n",
       " 'desk',\n",
       " 'balcony',\n",
       " 'telephone',\n",
       " 'field',\n",
       " 'fireplace',\n",
       " 'fan',\n",
       " 'palm',\n",
       " 'sand',\n",
       " 'river',\n",
       " 'skin',\n",
       " 'canopy',\n",
       " 'bridge',\n",
       " 'blotchy',\n",
       " 'sheep',\n",
       " 'bookcase',\n",
       " 'bedclothes',\n",
       " 'cow',\n",
       " 'dotted',\n",
       " 'land',\n",
       " 'bar',\n",
       " 'ball',\n",
       " 'grandstand',\n",
       " 'bumpy',\n",
       " 'tower',\n",
       " 'plane',\n",
       " 'pitted',\n",
       " 'marbled',\n",
       " 'blade',\n",
       " 'cracked',\n",
       " 'embankment',\n",
       " 'flecked',\n",
       " 'scaly',\n",
       " 'wrinkled',\n",
       " 'freckled',\n",
       " 'honeycombed',\n",
       " 'crystalline',\n",
       " 'cobwebbed',\n",
       " 'grooved',\n",
       " 'washer',\n",
       " 'waterfall',\n",
       " 'cradle',\n",
       " 'smoke',\n",
       " 'ship',\n",
       " 'exhibitor',\n",
       " 'eiderdown',\n",
       " 'cd',\n",
       " 'cockpit',\n",
       " 'controls',\n",
       " 'slide',\n",
       " 'ruins',\n",
       " 'terrace',\n",
       " 'bandstand',\n",
       " 'synthesizer',\n",
       " 'lockers',\n",
       " 'cabin',\n",
       " 'dam',\n",
       " 'shed',\n",
       " 'shops',\n",
       " 'stalls',\n",
       " 'village',\n",
       " 'mosque',\n",
       " 'rudder']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = y_concepts.index('field')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    mountain_test = net(X_test[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = F.cosine_similarity(mountain_test.unsqueeze(0), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bandstand', 'lockers', 'mosque', 'waterfall', 'ruins']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5 = np.argpartition(t.numpy(), -5)[-5:]\n",
    "c = [y_concepts[i] for i in top_5]\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
