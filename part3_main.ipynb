{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "from random import randint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/raid/home/arend036/msc_pim/Thesis-Scripts'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_EMBEDDING_PATH = '/mnt/guanabana/raid/data/datasets/GloVe/pretrained' \n",
    "GLOVE_PATH = WORD_EMBEDDING_PATH + '/glove.42B.300d.txt'\n",
    "CAVS_PATH = '../data/filtered_broden_cavs.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CAVS_PATH, 'rb') as handle:\n",
    "        cavs_broden = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47fef16314004f5e9f189a82601fec8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# takes about 4min to run on guanabana\n",
    "\n",
    "embedding_dict = {} # 1.9M words\n",
    "\n",
    "with open(GLOVE_PATH, 'r', encoding=\"utf-8\") as f:\n",
    "    for line in tqdm.notebook.tqdm(f):\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], 'float32')\n",
    "        embedding_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = list(cavs_broden.keys())\n",
    "embedding_concepts = []\n",
    "\n",
    "for c in concepts:\n",
    "    if c in embedding_dict.keys():\n",
    "        embedding_concepts.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all the concepts which have a concept activation vector and have a word embedding, the CAVs are concatenated into a matrix. Also the matching word embeddings are concatenated into a matrix. <br>\n",
    "These are then split in 75% training and 25% test data and converted into a TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cavs = torch.from_numpy(cavs_broden[embedding_concepts[0]]['cav']).float()\n",
    "y_word_vec = torch.from_numpy(embedding_dict[embedding_concepts[0]]).unsqueeze(0).float()\n",
    "\n",
    "for i in range(1, len(embedding_concepts)):\n",
    "    cav = torch.from_numpy(cavs_broden[embedding_concepts[i]]['cav']).float()\n",
    "    x_cavs = torch.cat((x_cavs, cav), 0)\n",
    "    \n",
    "    word_vec = torch.from_numpy(embedding_dict[embedding_concepts[i]]).unsqueeze(0).float()\n",
    "    y_word_vec = torch.cat((y_word_vec, word_vec), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly sample 25% indices of the matrices \n",
    "random.seed(42)\n",
    "random_idxs = random.sample(range(len(embedding_concepts)), 80)\n",
    "\n",
    "\n",
    "X_train = np.delete(x_cavs, random_idxs, axis=0)\n",
    "X_test = x_cavs[random_idxs,:]\n",
    "\n",
    "y_train = np.delete(y_word_vec, random_idxs, axis=0)\n",
    "y_test = y_word_vec[random_idxs,:]\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 10)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a simple neural network which is a linear function between the concept activation vectors and the word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(2048, 300)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "net = Net()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the optimizer and the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.7040, grad_fn=<MseLossBackward>)\n",
      "tensor(1.6489, grad_fn=<MseLossBackward>)\n",
      "tensor(0.7474, grad_fn=<MseLossBackward>)\n",
      "tensor(0.4251, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2715, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1880, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1369, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0777, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0595, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for data in train_loader:\n",
    "        X, y = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(X)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = '../models/cav_to_word_net.pth'\n",
    "torch.save(net.state_dict(), MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = list(net.parameters())[0]\n",
    "\n",
    "bias = net.fc1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_concepts.index('mountain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "mountain_emb = embedding_dict['mountain'].reshape(300,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = (torch.from_numpy(mountain_emb) - bias.unsqueeze(1)) / weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 1])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
