{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from p1_MakeVectorDictionary.ipynb\n",
      "Importing Jupyter notebook from p1_GetVectorFromImage.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import nbimporter\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn import linear_model\n",
    "\n",
    "from p1_MakeVectorDictionary import MakeVectorDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetCav(concept, num_concept_imgs, num_counter_imgs, training_dataframe,\n",
    "          basenet, out_layer, broden_dataset):\n",
    "    \n",
    "    \n",
    "    # create filenames to store the dictionaries of tensors\n",
    "    concept_filename = concept + '_' + str(num_concept_imgs) + 'imgs.pickle'\n",
    "    counter_filename = 'counter_' + concept + '_' + str(num_counter_imgs) + 'imgs.pickle'\n",
    "    \n",
    "    \n",
    "    \n",
    "    #### GET RANDOM CONCEPT IMAGES\n",
    "    \n",
    "    # get the row indices of images which are labelled with the concept\n",
    "    concept_idxs = training_dataframe.loc[training_dataframe[concept] == 1, 'image'].index.tolist()\n",
    "    #print('The concept \"%s\" is present in %d images' % (concept, len(concept_idxs)))\n",
    "    \n",
    "    # if the amount of random concept images is larger than the total amount of images labelled with the concept,\n",
    "    # raise a ValueError\n",
    "    if num_concept_imgs > len(concept_idxs):\n",
    "        raise ValueError ('The number of specified concept images (%d) is larger than the total amount of images labelled with the concept (%d)' \n",
    "                          % (num_concept_imgs, len(concept_idxs)))\n",
    "        \n",
    "    # create a dictionary storing the tensors if it does not exist yet, otherwise read the dictionary\n",
    "    if not os.path.exists(os.path.join('../data/', concept_filename)):\n",
    "        \n",
    "        random_concept_imgs = random.sample(concept_idxs, num_concept_imgs)\n",
    "        #print('Selecting random concept images')\n",
    "        \n",
    "        concept_vector_dict = MakeVectorDictionary(basenet, out_layer, broden_dataset, random_concept_imgs, concept_filename)\n",
    "    else:\n",
    "        with open(os.path.join('../data/', concept_filename), 'rb') as handle:\n",
    "            concept_vector_dict = pickle.load(handle)\n",
    "        \n",
    "        random_concept_imgs = list(map(lambda x: int(x), list(concept_vector_dict.keys())))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #### GET RANDOM COUNTER IMAGES\n",
    "    #print('Selecting random counter images')\n",
    "    \n",
    "    # create a dictionary storing the tensors of the random counter examples\n",
    "    if not os.path.exists(os.path.join('../data/', counter_filename)):\n",
    "        # get row indices of images not labelled with the concept\n",
    "        counter_idxs = [i for i in range(len(training_dataframe)) if i not in concept_idxs]\n",
    "    \n",
    "        # sample random images for the counter images\n",
    "        random_counter_imgs = random.sample(counter_idxs, num_counter_imgs)\n",
    "        \n",
    "        counter_vector_dict = MakeVectorDictionary(basenet, out_layer, broden_dataset, random_counter_imgs, counter_filename)\n",
    "    else:\n",
    "        with open(os.path.join('../data/', counter_filename), 'rb') as handle:\n",
    "            counter_vector_dict = pickle.load(handle)\n",
    "        \n",
    "        random_counter_imgs = list(map(lambda x: int(x), list(counter_vector_dict.keys())))\n",
    "    \n",
    "    \n",
    "    ##### TRAIN A LINEAR CLASSIFIER\n",
    "    \n",
    "    # The linear classifier requires a matrix of np.arrays to fit a model on. \n",
    "    # A tensor is initialized to which the other tensors can be added\n",
    "    \n",
    "    concept_keys = list(concept_vector_dict.keys())\n",
    "    concept_tensors = concept_vector_dict[concept_keys[0]].unsqueeze(0)\n",
    "    for i in range(1, num_concept_imgs):\n",
    "        temp_concept_tensor = concept_vector_dict[concept_keys[i]].unsqueeze(0)\n",
    "        concept_tensors = torch.cat((concept_tensors, temp_concept_tensor),0)\n",
    "    \n",
    "    counter_keys = list(counter_vector_dict.keys())\n",
    "    counter_tensors = counter_vector_dict[counter_keys[0]].unsqueeze(0)\n",
    "    for i in range(1, num_counter_imgs):\n",
    "        temp_tensor = counter_vector_dict[counter_keys[i]].unsqueeze(0)\n",
    "        counter_tensors = torch.cat((counter_tensors, temp_tensor),0)\n",
    "    \n",
    "    # concatenate all tensors to the same array\n",
    "    X = torch.cat((concept_tensors, counter_tensors), 0)\n",
    "    X = X.numpy()\n",
    "    \n",
    "    # create labels for the tensors\n",
    "    # 1 = concepts, 0 = not concept\n",
    "    y = np.ones(num_concept_imgs)\n",
    "    y = np.append(y, np.zeros(num_counter_imgs))\n",
    "    \n",
    "    # create a linear model and fit it to the data\n",
    "    lm = linear_model.SGDClassifier()\n",
    "    lm.fit(X, y)\n",
    "    \n",
    "    cav = lm.coef_\n",
    "    \n",
    "    return random_concept_imgs, random_counter_imgs, cav, lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
