{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if access to laptop Pim: True \n",
    "# else: False\n",
    "LAPTOP_PIM = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to concept overview csv\n",
    "csv_path = '../data/concept_overview_latent_space.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the dataframes\n",
    "if os.path.exists(csv_path):\n",
    "    cdf = pd.read_csv(csv_path, index_col=0)\n",
    "else:\n",
    "    training_concepts = pd.read_csv('../data/training_tau_latent.csv', index_col = 0)\n",
    "    training_concepts.sort_index(inplace=True)\n",
    "    training_concepts['Training tau'] = training_concepts['Training tau'].round(3)\n",
    "    print(training_concepts.shape)\n",
    "    training_concepts.head();\n",
    "\n",
    "    latent_concept_pairs = pd.read_csv('../data/broden_concepts_glove_neighbors.csv', index_col = 0)\n",
    "    print(latent_concept_pairs.shape)\n",
    "    latent_concept_pairs.head();\n",
    "\n",
    "    cdf= training_concepts.merge(latent_concept_pairs, \n",
    "                                 how='left', \n",
    "                                 left_on = 'Training Concept', \n",
    "                                 right_on='Broden concept').drop(columns= ['Broden concept'])\n",
    "    cdf['GloVe Concept'] = cdf['GloVe neighbor']\n",
    "    cdf.drop(columns=['GloVe neighbor'], inplace=True)\n",
    "    print(cdf.shape)\n",
    "\n",
    "    latent_concepts = pd.read_csv('../data/new_glove_tau_latent.csv', index_col =0)\n",
    "\n",
    "    cdf = cdf.merge(latent_concepts,\n",
    "                    how='left', \n",
    "                    left_on = 'GloVe Concept', \n",
    "                    right_on = 'New GloVe Concept').drop(columns=['New GloVe Concept'])\n",
    "    cdf['GloVe tau'] = cdf['GloVe tau'].round(3)\n",
    "\n",
    "    cdf.to_csv('../data/concept_overview_latent_space.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training tau</th>\n",
       "      <th>Training Concept</th>\n",
       "      <th>GloVe Concept</th>\n",
       "      <th>GloVe tau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>0.479</td>\n",
       "      <td>ocean</td>\n",
       "      <td>waters</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2101</th>\n",
       "      <td>0.479</td>\n",
       "      <td>ocean</td>\n",
       "      <td>oceans</td>\n",
       "      <td>0.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2102</th>\n",
       "      <td>0.479</td>\n",
       "      <td>ocean</td>\n",
       "      <td>seas</td>\n",
       "      <td>0.248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103</th>\n",
       "      <td>0.479</td>\n",
       "      <td>ocean</td>\n",
       "      <td>pacific</td>\n",
       "      <td>0.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>0.479</td>\n",
       "      <td>ocean</td>\n",
       "      <td>coastline</td>\n",
       "      <td>0.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>0.479</td>\n",
       "      <td>ocean</td>\n",
       "      <td>coastal</td>\n",
       "      <td>0.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>0.479</td>\n",
       "      <td>ocean</td>\n",
       "      <td>coasts</td>\n",
       "      <td>0.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>0.479</td>\n",
       "      <td>ocean</td>\n",
       "      <td>coral</td>\n",
       "      <td>0.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>0.479</td>\n",
       "      <td>ocean</td>\n",
       "      <td>arctic</td>\n",
       "      <td>0.507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>0.479</td>\n",
       "      <td>ocean</td>\n",
       "      <td>islands</td>\n",
       "      <td>0.470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Training tau Training Concept GloVe Concept  GloVe tau\n",
       "2100         0.479            ocean        waters      0.398\n",
       "2101         0.479            ocean        oceans      0.326\n",
       "2102         0.479            ocean          seas      0.248\n",
       "2103         0.479            ocean       pacific      0.234\n",
       "2104         0.479            ocean     coastline      0.455\n",
       "2105         0.479            ocean       coastal      0.211\n",
       "2106         0.479            ocean        coasts      0.209\n",
       "2107         0.479            ocean         coral      0.494\n",
       "2108         0.479            ocean        arctic      0.507\n",
       "2109         0.479            ocean       islands      0.470"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf.loc[cdf['Training Concept'] == 'ocean', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_concepts = pd.read_csv('../data/training_tau_latent.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training tau</th>\n",
       "      <th>Training Concept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0.080587</td>\n",
       "      <td>cottage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Training tau Training Concept\n",
       "293      0.080587          cottage"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_concepts.loc[training_concepts['Training Concept'] == 'cottage',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load data to visualize images\n",
    "\n",
    "#load transformed GloVe data\n",
    "z2 = np.load('../data/z2.npy')\n",
    "\n",
    "#load the corresponding concepts\n",
    "with open('../data/embedding_concepts.data', 'rb') as filehandle:\n",
    "    embedding_concepts = pickle.load(filehandle)\n",
    "\n",
    "#load the glove neighbors aka the new concepts\n",
    "with open('../data/glove_neighbors_concepts.data', 'rb') as filehandle:\n",
    "    glove_neighbors = pickle.load(filehandle)\n",
    "\n",
    "#load the transformed image representations\n",
    "transformed_imgs = np.load('../data/transformed_images.npy')\n",
    "transformed_ixs = np.load('../data/transformed_images_ixs.npy')\n",
    "\n",
    "#load all SoN info\n",
    "son_info = pd.read_csv('../data/son_votes.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine similarity for all original CAV concepts with the transformed images\n",
    "training_neigh_similarity = cosine_similarity(z2.T[:len(embedding_concepts), :], transformed_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the new concept vectors\n",
    "new_concept_activations = z2.T[len(embedding_concepts):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the cosine similarity between the new concepts and the transformed imaged\n",
    "cossim_latent = cosine_similarity(new_concept_activations, transformed_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the new GloVe concepts, extract the top 5% images with the highest concept score and calculate the average concept score for those images. Sort the concepts on descending order to create a list of most common concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "093aa18e25e743baac589398937a5cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2246.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "latent_concept_score = np.load('../data/latent_concept_score.npy')\n",
    "\n",
    "# convert matrix to dataframe\n",
    "df = pd.DataFrame(latent_concept_score)\n",
    "\n",
    "# create empty matrix\n",
    "top5_imgs = np.zeros((1375, len(glove_neighbors)))\n",
    "\n",
    "# for each concept extract the top 5% images with the largest concept score\n",
    "for i in trange(len(glove_neighbors)):\n",
    "    top5_score = df.iloc[:, i].nlargest(1375)\n",
    "    top5_imgs[:, i] = top5_score\n",
    "\n",
    "# calculate the average scores\n",
    "mean_scores = top5_imgs.mean(axis=0)\n",
    "\n",
    "# sort the mean scores\n",
    "top5_concepts = [glove_neighbors[i] for i in mean_scores.argsort()[::-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function saves the images closest related to Broden concept in the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to save a number of concept images from the Broden concepts\n",
    "%matplotlib inline\n",
    "def save_broden_concept_imgs_to_drive(coi, num_imgs):\n",
    "    \n",
    "    img_dir = '../ICPR_Paper/concept_images/' + str(num_imgs) + '/'\n",
    "    if not os.path.exists(img_dir):\n",
    "        os.mkdir(img_dir)\n",
    "    \n",
    "    save_dir = '../ICPR_Paper/concept_images/' + str(num_imgs) + '/' + coi + '_broden.png'\n",
    "    \n",
    "    if not os.path.exists(save_dir):\n",
    "        \n",
    "        # get the similarity for the concept of interest\n",
    "        coi_sim = training_neigh_similarity[embedding_concepts.index(coi)]\n",
    "\n",
    "        #get the n most similar images\n",
    "        coi_neigh = coi_sim.argsort()[::-1][:num_imgs]\n",
    "        coi_neigh = [transformed_ixs[j] for j in coi_neigh]\n",
    "\n",
    "        paths = []\n",
    "        scores = []\n",
    "\n",
    "        for i in coi_neigh:\n",
    "            img_name = son_info.loc[i, 'ID']\n",
    "            img_score = son_info.loc[i, 'Average']\n",
    "\n",
    "            paths.append('../son_images/images/' + str(img_name) + '.jpg')\n",
    "            scores.append(img_score)\n",
    "\n",
    "        #sort the images according to ascencing scenicness scores\n",
    "        paths = [paths[i] for i in np.asarray(scores).argsort()]\n",
    "\n",
    "        img_transform = transforms.Compose([transforms.CenterCrop(400)])\n",
    "        fig = plt.figure(figsize=(15,15))\n",
    "        ax = [fig.add_subplot(1, num_imgs, i+1) for i in range(num_imgs)]\n",
    "\n",
    "        for idx, a in enumerate(ax):\n",
    "            img = Image.open(paths[idx])\n",
    "            crop_img = img_transform(img)\n",
    "            crop_img = np.asarray(crop_img)\n",
    "            a.axis('off')\n",
    "            a.imshow(crop_img)\n",
    "\n",
    "        fig.subplots_adjust(wspace=0, hspace=0)\n",
    "#         plt.savefig(save_dir, bbox_inches='tight')\n",
    "#         fig.clf()\n",
    "#         plt.close(fig)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for coi in tqdm(embedding_concepts):\n",
    "#     save_broden_concept_imgs_to_drive(coi, 8)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_broden_concept_imgs_to_drive' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-658fb03fc5db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_broden_concept_imgs_to_drive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'canyon'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'save_broden_concept_imgs_to_drive' is not defined"
     ]
    }
   ],
   "source": [
    "save_broden_concept_imgs_to_drive('canyon', 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function saves the images for the new GloVe concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_glove_neighbor_imgs_to_drive(coi, num_imgs):\n",
    "    img_dir = '../ICPR_Paper/concept_images/' + str(num_imgs) +'/'\n",
    "    if not os.path.exists(img_dir):\n",
    "        os.mkdir(img_dir)\n",
    "    \n",
    "    save_dir = '../ICPR_Paper/concept_images/' + str(num_imgs) + '/' + coi + '.png'\n",
    "    if not os.path.exists(save_dir):\n",
    "        cidx = glove_neighbors.index(coi)\n",
    "        c_neigh = cossim_latent[cidx].flatten()\n",
    "        c_imgs = c_neigh.argsort()[::-1][:num_imgs]\n",
    "        ix_imgs = [transformed_ixs[j] for j in c_imgs]\n",
    "\n",
    "        paths = []\n",
    "        scores = []\n",
    "\n",
    "        for i in ix_imgs:\n",
    "            img_name = son_info.loc[i, 'ID']\n",
    "            img_score = son_info.loc[i, 'Average']\n",
    "\n",
    "            paths.append('../son_images/images/' + str(img_name) + '.jpg')\n",
    "            scores.append(img_score)\n",
    "        \n",
    "        #sort the images according to ascencing scenicness scores\n",
    "        paths = [paths[i] for i in np.asarray(scores).argsort()]\n",
    "\n",
    "        img_transform = transforms.Compose([transforms.CenterCrop(400)])\n",
    "\n",
    "        fig = plt.figure(figsize=(15,15))\n",
    "        ax = [fig.add_subplot(1, num_imgs, i+1) for i in range(num_imgs)]\n",
    "\n",
    "        for idx, a in enumerate(ax):\n",
    "            img = Image.open(paths[idx])\n",
    "            crop_img = img_transform(img)\n",
    "            crop_img = np.asarray(crop_img)\n",
    "            a.axis('off')\n",
    "            a.imshow(crop_img)\n",
    "        fig.subplots_adjust(wspace=0, hspace=0)\n",
    "#         plt.savefig(save_dir, bbox_inches='tight')\n",
    "#         fig.clf()\n",
    "#         plt.close(fig)\n",
    "        plt.show()\n",
    "#     else:\n",
    "#         print(coi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for coi in tqdm(glove_neighbors):\n",
    "#     save_glove_neighbor_imgs_to_drive(coi, 8)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_glove_neighbor_imgs_to_drive('arctic', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to display the corresponding concepts and the nearest neighbor concepts from GloVe\n",
    "def viewImages(coi, num_imgs): \n",
    "    \n",
    "    # save Broden concept images\n",
    "    save_broden_concept_imgs_to_drive(coi, num_imgs)\n",
    "        \n",
    "    if not os.path.exists('../ICPR_Paper/concept_and_neighbors/' + str(num_imgs) + '/'):\n",
    "        os.mkdir('../ICPR_Paper/concept_and_neighbors/' + str(num_imgs) + '/')\n",
    "    \n",
    "    save_dir = '../ICPR_Paper/concept_and_neighbors/' + str(num_imgs) + '/' + coi + '.png'    \n",
    "    \n",
    "    # search for the neighboring GloVe concepts\n",
    "    neighbors = list(cdf.loc[cdf['Training Concept'] == coi, 'GloVe Concept'].values)\n",
    "    n_concepts_ix = np.asarray([top5_concepts.index(i) for i in neighbors]).argsort()[:4]\n",
    "    neighbor_concepts = [neighbors[c] for c in n_concepts_ix]\n",
    "    \n",
    "    paths = ['../ICPR_Paper/concept_images/' + str(num_imgs) + '/' + coi + '.png']    \n",
    "    correlations = [round(cdf.loc[cdf['Training Concept'] == 'embankment', 'Training tau'].values[0],3)]\n",
    "    \n",
    "    # for each neighboring concepts, save the corresponding images and the image paths\n",
    "    for c in neighbor_concepts:\n",
    "        save_glove_neighbor_imgs_to_drive(c, num_imgs)\n",
    "        if c == '.':\n",
    "            concept_img = '../ICPR_Paper/concept_images/' + str(num_imgs) + '/..png.png'\n",
    "        else:\n",
    "            concept_img = '../ICPR_Paper/concept_images/' + str(num_imgs) + '/' + c + '.png'\n",
    "        paths.append(concept_img)\n",
    "        correlations.append(round(cdf.loc[cdf['GloVe Concept'] == c, 'GloVe tau'].values[0],3))\n",
    "\n",
    "    # create a image with the Broden concept and the neighboring concepts    \n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    ax = [fig.add_subplot(len(neighbor_concepts)+1, 1, i+1) for i in range(len(neighbor_concepts)+1)]\n",
    "\n",
    "    for idx, a in enumerate(ax):\n",
    "        img = Image.open(paths[idx])\n",
    "        a.axis('off')\n",
    "        if idx == 0:\n",
    "            a.set_title(coi + ' (Broden concept)' + ' ' + str(correlations[idx]))\n",
    "        else:\n",
    "            a.set_title(neighbor_concepts[idx-1] + ' ' + str(correlations[idx]))\n",
    "        a.imshow(img)\n",
    "    fig.subplots_adjust(wspace=0, hspace=0.4)\n",
    "    plt.savefig(save_dir, bbox_inches='tight')\n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewImages('pasture', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6190db88fad9408d99b1803262dbee9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=302.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for c in tqdm(embedding_concepts):\n",
    "    viewImages(c, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the neighbors for concept \"bass\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1119\n"
     ]
    }
   ],
   "source": [
    "coi = 'bass'\n",
    "cidx = glove_neighbors.index(coi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_neighbors = cosine_similarity(new_concept_activations[cidx, :].reshape(1,-1), z2.T[:len(embedding_concepts), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10 = c_neighbors.flatten().argsort()[::-1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guitar\n",
      "keyboard\n",
      "lake\n",
      "neck\n",
      "alcove\n",
      "sand\n",
      "pitch\n",
      "metal\n",
      "bridge\n",
      "sea\n"
     ]
    }
   ],
   "source": [
    "for i in top10:\n",
    "    print(embedding_concepts[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order the neighboring concepts based on the average concepts score of the top 5% images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['coastline', 'waters', 'coral', 'seas', 'islands', 'coasts', 'coastal', 'oceans', 'arctic', 'pacific']\n"
     ]
    }
   ],
   "source": [
    "coi = 'ocean'\n",
    "\n",
    "neighbors = list(cdf.loc[cdf['Training Concept'] == coi, 'GloVe Concept'].values)\n",
    "n_concepts_ix = np.asarray([top5_concepts.index(i) for i in neighbors]).argsort()\n",
    "neighbor_concepts = [neighbors[c] for c in n_concepts_ix]\n",
    "print(neighbor_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
